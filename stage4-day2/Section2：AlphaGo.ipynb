{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e4f5945",
   "metadata": {},
   "source": [
    "# Section2：AlphaGo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316df806",
   "metadata": {},
   "source": [
    "## AlphaGoとは\n",
    "Google DeepMindによって開発されたコンピュータ囲碁プログラムである。\n",
    "コンピュータが人間に打ち勝つことが最も難しいと考えられてきた分野である囲碁において、人工知能が勝利を収めたことは、単なる一競技の勝敗を越え、人工知能の有用性を広く知らしめるものとなり、世界的AIブームを呼び起こすきっかけともなった。\n",
    "\n",
    "引用：[Wikipedia](https://ja.wikipedia.org/wiki/AlphaGo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2196f66",
   "metadata": {},
   "source": [
    "## Alpha Go (Lee)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0935bb",
   "metadata": {},
   "source": [
    "### PolicyNet(方策関数)\n",
    "\n",
    "入力データとして、盤面の１９×１９を４８チャンネルとしている。石（自石、敵石、空白）や着手履歴などで合計４８チャンネルが入力データとなる。 \\\n",
    "出力データは、盤面の１９×１９となる。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d252a79",
   "metadata": {},
   "source": [
    "### ValueNet(価値関数)\n",
    "\n",
    "入力データとして、盤面の１９×１９を４８チャンネルとしている。石（自石、敵石、空白）や着手履歴などで合計４８チャンネルが入力データとなる。 \\\n",
    "出力データは、-∞～∞を-1～1に変換して１個の数値データで勝ち負けを判断する。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9dd4647",
   "metadata": {},
   "source": [
    "### RollOutPolicy\n",
    "\n",
    "- NNではなく線形の方策関数\n",
    "- 探索中に高速に着手確率を出すために使用される"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37cb5cc0",
   "metadata": {},
   "source": [
    "### PolicyNetの教師あり学習\n",
    "- 3000万局面分の棋譜データを教師データとし、教師と同じ着手を予測できるよう学習を行った。\n",
    "- 具体的には、教師が着手した手を1とし残りを0とした19×19次元の配列を教師とし、それを分類問題として学習した。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47f9af1",
   "metadata": {},
   "source": [
    "### PolicyNetの強化学習\n",
    "\n",
    "- PolicyPoolとは、PolicyNetの強化学習の過程を500Iteraionごとに記録し保存しておいたものである。\n",
    "- 現状のPolicyNetとPolicyPoolからランダムに選択されたPolicyNetと対局シミュレーションを行い、その結果を用いて方策勾配法で学習を行った。\n",
    "- 現状のPolicyNet同士の対局ではなく、PolicyPoolに保存されているものとの対局を使用する理由は、対局に幅を持たせて過学習を防ごうというのが主である。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee104619",
   "metadata": {},
   "source": [
    "### ValueNetの学習\n",
    "- PolicyNetを使用して対局シミュレーションを行い、その結果の勝敗を教師として学習した。\n",
    "- 教師データ作成の手順は\n",
    " 1. SL PolicyNet(教師あり学習で作成したPolicyNet)でN手まで打つ。\n",
    " 1. N+1手目の手をランダムに選択し、その手で進めた局面をS（N+1）とする。\n",
    " 1. S（N+1）からRL PolicyNet（強化学習で作成したPolicyNet）で終局まで打ち、その勝敗報酬をRとする。\n",
    "- S(N+1）とRを教師データ対とし、損失関数を平均二乗誤差とし、回帰問題として学習した。\n",
    "- N手までとN+1手からのPolicyNetを別々にしてある理由は、過学習を防ぐためであると論文では説明されている。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f037eb15",
   "metadata": {},
   "source": [
    "## AlphaGo (Lee) とAlphaGo Zeroの違い\n",
    "1. 教師あり学習を一切行わず、強化学習のみで作成\n",
    "1. 特徴入力からヒューリスティックな要素を排除し、石の配置のみにした\n",
    "1. PolicyNetとValueNetを１つのネットワークに統合した\n",
    "1. Residual Net（後述）を導入した\n",
    "1. モンテカルロ木探索からRollOutシミュレーションをなくした"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96dab8b",
   "metadata": {},
   "source": [
    "### Residual Network\n",
    "- ネットワークにショートカット構造を追加して、勾配の爆発、消失を抑える効果を狙ったもの\n",
    "- Residula Networkを使うことにより、100層を超えるネットワークでの安定した学習が可能となった\n",
    "- 基本構造はConvolution→BatchNorm→ReLU→Convolution→BatchNorm→Add→ReLUのBlockを１単位にして積み重ねる形となる\n",
    "- また、Resisual Networkを使うことにより層数の違うNetworkのアンサンブル効果が得られているという説もある"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1a0754",
   "metadata": {},
   "source": [
    "## Residual Networkの派生形\n",
    "### Residual Blockの工夫\n",
    "\n",
    "#### Bottleneck\n",
    "1×1KernelのConvolutionを利用し、1層目で次元削減を行って3層目で次元を復元する３層構造にし、２層のものと比べて計算量はほぼ同じだが１層増やせるメリットがある、としたもの\n",
    "\n",
    "##### PreActivation \n",
    "ResidualBlockの並びをBatchNorm→ReLU→Convolution→BatchNorm→ReLU→Convolution→Addとすることにより性能が上昇したとするもの\n",
    "\n",
    "#### Network構造の工夫\n",
    "\n",
    "##### WideResNet \n",
    "ConvolutionのFilter数をk倍にしたResNet。１倍→k倍ｘブロック→2*k倍yブロックと段階的に幅を増やしていくのが一般的。Filter数を増やすことにより、浅い層数でも深い層数のものと同等以上の精度となり、またGPUをより効率的に使用できるため学習も早い\n",
    "\n",
    "##### PyramidNet \n",
    "WideResNetで幅が広がった直後の層に過度の負担がかかり精度を落とす原因となっているとし、段階的にではなく、各層でFilter数を増やしていくResNet。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6c08ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
