{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be179538",
   "metadata": {},
   "source": [
    "# Section5：Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c84b0f0",
   "metadata": {},
   "source": [
    "# Seq2seqとは？\n",
    "## 系列(Sequence)を入力として、系列を出力するもの\n",
    "- Encoder-Decoderモデルとも呼ばれる \n",
    "- 入力系列がEncode(内部状態に変換)され、内部状態からDecode(系列に変換)する \n",
    "- 実応用上も、入力・出力共に系列情報なものは多い \n",
    " - 翻訳 (英語→日本語) \n",
    " - 音声認識 (波形→テキスト) \n",
    " - チャットボット (テキスト→テキスト)\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddea47f7",
   "metadata": {},
   "source": [
    "## 言語モデルとは\n",
    "言語モデルは単語の並びに確率を与える\n",
    "\n",
    "- 単語の並びに対して尤度(それがどれだけ起こり得るか)、すなわち、文章として自然かを確率で評価する \n",
    "- 例) \n",
    " - You say goodbye → 0.092 (自然) \n",
    " - You say good die → 0.00000032 (不自然) \n",
    "- 数式的には同時確率を事後確率に分解して表せる\n",
    "\n",
    "### 時刻t-1までの情報で、時刻tの事後確率を求めることが目標 \n",
    "→これで同時確率が計算できる"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812dfd54",
   "metadata": {},
   "source": [
    "## RNN x 言語モデル\n",
    "\n",
    "- RNNは系列情報を内部状態に変換することができる \n",
    "- 文章の各単語が現れる際の同時確率は、事後確率で分解できる \n",
    " - したがって、事後確率を求めることがRNNの目標になる \n",
    "- 言語モデルを再現するようにRNNの重みが学習されていれば、ある時点の次の単語を予測することができる \n",
    " - 先頭単語を与えれば文章を生成することも可能"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8f71d7",
   "metadata": {},
   "source": [
    "## 実装演習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "976714b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\takas\\anaconda3\\envs\\ml\\lib\\site-packages\\wheel\\pep425tags.py:80: RuntimeWarning: Config variable 'Py_DEBUG' is unset, Python ABI tag may be incorrect\n",
      "  if get_flag('Py_DEBUG',\n",
      "ERROR: torch-0.4.0-cp39-cp39-linux_x86_64.whl is not a supported wheel on this platform.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8.2+cpu\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "from os import path\n",
    "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
    "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
    "\n",
    "accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
    "\n",
    "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.0-{platform}-linux_x86_64.whl torchvision\n",
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8313fc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !bitsadmin.exe /TRANSFER  https://www.dropbox.com/s/9narw5x4uizmehh/utils.py\n",
    "# !mkdir images data\n",
    "\n",
    "# # data取得\n",
    "# !bitsadmin.exe /TRANSFER https://www.dropbox.com/s/o4kyc52a8we25wy/dev.en  data/\n",
    "# !bitsadmin.exe /TRANSFER https://www.dropbox.com/s/kdgskm5hzg6znuc/dev.ja  data/\n",
    "# !bitsadmin.exe /TRANSFER https://www.dropbox.com/s/gyyx4gohv9v65uh/test.en  data/\n",
    "# !bitsadmin.exe /TRANSFER https://www.dropbox.com/s/hotxwbgoe2n013k/test.ja  data/\n",
    "# !bitsadmin.exe /TRANSFER https://www.dropbox.com/s/5lsftkmb20ay9e1/train.en  data/\n",
    "# !bitsadmin.exe /TRANSFER https://www.dropbox.com/s/ak53qirssci6f1j/train.ja  data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "570e32ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ドライブ C のボリューム ラベルがありません。\n",
      " ボリューム シリアル番号は CAF3-F41E です\n",
      "\n",
      " C:\\Users\\takas\\rabbit\\rabbit-report\\stage4-day2\\data のディレクトリ\n",
      "\n",
      "2021/12/27  01:38    <DIR>          .\n",
      "2021/12/27  01:38    <DIR>          ..\n",
      "2021/12/27  01:36            17,054 dev.en\n",
      "2021/12/27  01:37            27,781 dev.ja\n",
      "2021/12/27  01:37            17,301 test.en\n",
      "2021/12/27  01:37            27,793 test.ja\n",
      "2021/12/27  01:37         1,701,356 train.en\n",
      "2021/12/27  01:38         2,784,447 train.ja\n",
      "               6 個のファイル           4,575,732 バイト\n",
      "               2 個のディレクトリ  344,095,592,448 バイトの空き領域\n"
     ]
    }
   ],
   "source": [
    "! dir data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccf3a438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8.2+cpu\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from nltk import bleu_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils.rnn import pad_packed_sequence, pack_padded_sequence\n",
    "from utils import Vocab\n",
    "\n",
    "# デバイスの設定\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "torch.manual_seed(1)\n",
    "random_state = 42\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c73bbe5",
   "metadata": {},
   "source": [
    "# 1.データセットの準備\n",
    "英語-日本語の対訳コーパスである、Tanaka Corpus ( http://www.edrdg.org/wiki/index.php/Tanaka_Corpus )を使います。<br>\n",
    "今回はそのうちの一部分を取り出したsmall_parallel_enja: 50k En/Ja Parallel Corpus for Testing SMT Methods ( https://github.com/odashi/small_parallel_enja )を使用します。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c599542",
   "metadata": {},
   "source": [
    "## 1.1データの読み込みと単語の分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81b24614",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    # テキストファイルからデータを読み込むメソッド\n",
    "    data = []\n",
    "    for line in open(file_path, encoding='utf-8'):\n",
    "        words = line.strip().split()  # スペースで単語を分割\n",
    "        data.append(words)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02d8c330",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = load_data('./data/train.en')\n",
    "train_Y = load_data('./data/train.ja')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d089d1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練データと検証データに分割\n",
    "train_X, valid_X, train_Y, valid_Y = train_test_split(train_X, train_Y, test_size=0.2, random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e84f73",
   "metadata": {},
   "source": [
    "この時点で入力と教師データは以下のようになっています"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4433bbf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data ['where', 'shall', 'we', 'eat', 'tonight', '?']\n",
      "valid data ['you', 'may', 'extend', 'your', 'stay', 'in', 'tokyo', '.']\n"
     ]
    }
   ],
   "source": [
    "print('train data', train_X[0])\n",
    "print('valid data', valid_X[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16180c3e",
   "metadata": {},
   "source": [
    "## 1.2単語辞書の作成\n",
    "データセットに登場する各単語にIDを割り振る"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4276a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# まず特殊トークンを定義しておく\n",
    "PAD_TOKEN = '<PAD>'  # バッチ処理の際に、短い系列の末尾を埋めるために使う （Padding）\n",
    "BOS_TOKEN = '<S>'  # 系列の始まりを表す （Beggining of sentence）\n",
    "EOS_TOKEN = '</S>'  # 系列の終わりを表す （End of sentence）\n",
    "UNK_TOKEN = '<UNK>'  # 語彙に存在しない単語を表す （Unknown）\n",
    "PAD = 0\n",
    "BOS = 1\n",
    "EOS = 2\n",
    "UNK = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dff89dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_COUNT = 2  # 語彙に含める単語の最低出現回数 再提出現回数に満たない単語はUNKに置き換えられる\n",
    "\n",
    "# 単語をIDに変換する辞書の初期値を設定\n",
    "word2id = {\n",
    "    PAD_TOKEN: PAD,\n",
    "    BOS_TOKEN: BOS,\n",
    "    EOS_TOKEN: EOS,\n",
    "    UNK_TOKEN: UNK,\n",
    "    }\n",
    "\n",
    "# 単語辞書を作成\n",
    "vocab_X = Vocab(word2id=word2id)\n",
    "vocab_Y = Vocab(word2id=word2id)\n",
    "vocab_X.build_vocab(train_X, min_count=MIN_COUNT)\n",
    "vocab_Y.build_vocab(train_Y, min_count=MIN_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20a571ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "入力言語の語彙数： 3725\n",
      "出力言語の語彙数： 4405\n"
     ]
    }
   ],
   "source": [
    "vocab_size_X = len(vocab_X.id2word)\n",
    "vocab_size_Y = len(vocab_Y.id2word)\n",
    "print('入力言語の語彙数：', vocab_size_X)\n",
    "print('出力言語の語彙数：', vocab_size_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d83088",
   "metadata": {},
   "source": [
    "# 2.テンソルへの変換\n",
    "### 2.1 IDへの変換\n",
    "まずはモデルが文章を認識できるように、文章を単語IDのリストに変換します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c868757",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_to_ids(vocab, sentence):\n",
    "    # 単語(str)のリストをID(int)のリストに変換する関数\n",
    "    ids = [vocab.word2id.get(word, UNK) for word in sentence]\n",
    "    ids += [EOS]  # EOSを加える\n",
    "    return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "701c3337",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = [sentence_to_ids(vocab_X, sentence) for sentence in train_X]\n",
    "train_Y = [sentence_to_ids(vocab_Y, sentence) for sentence in train_Y]\n",
    "valid_X = [sentence_to_ids(vocab_X, sentence) for sentence in valid_X]\n",
    "valid_Y = [sentence_to_ids(vocab_Y, sentence) for sentence in valid_Y]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26cf29de",
   "metadata": {},
   "source": [
    "この時点で入力と教師データは以下のようになっている"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "88933a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data [132, 321, 28, 290, 367, 12, 2]\n",
      "valid data [8, 93, 3532, 36, 236, 13, 284, 4, 2]\n"
     ]
    }
   ],
   "source": [
    "print('train data', train_X[0])\n",
    "print('valid data', valid_X[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7106820",
   "metadata": {},
   "source": [
    "### 2.2 DataLoaderの定義\n",
    "データセットからバッチを取得するデータローダーを定義します\n",
    "- この際、長さの異なる複数の系列をバッチで並列に扱えるように、短い系列の末尾を特定のシンボル（`<PAD>`など）でパディングし、バッチ内の系列の長さを最長のものに合わせる\n",
    "- (batch_size, max_length)のサイズの行列を得るが、実際にモデルを学習させるときには、バッチをまたいで各時刻ごとに進めていくので、転置して(max_length, batch_size)の形に変える<br>（batch_first=Trueのオプションを使う場合は不要）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6c17b4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_seq(seq, max_length):\n",
    "    # 系列(seq)が指定の文長(max_length)になるように末尾をパディングする\n",
    "    res = seq + [PAD for i in range(max_length - len(seq))]\n",
    "    return res    \n",
    "\n",
    "\n",
    "class DataLoader(object):\n",
    "\n",
    "    def __init__(self, X, Y, batch_size, shuffle=False):\n",
    "        \"\"\"\n",
    "        :param X: list, 入力言語の文章（単語IDのリスト）のリスト\n",
    "        :param Y: list, 出力言語の文章（単語IDのリスト）のリスト\n",
    "        :param batch_size: int, バッチサイズ\n",
    "        :param shuffle: bool, サンプルの順番をシャッフルするか否か\n",
    "        \"\"\"\n",
    "        self.data = list(zip(X, Y))\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.start_index = 0\n",
    "        \n",
    "        self.reset()\n",
    "    \n",
    "    def reset(self):\n",
    "        if self.shuffle:  # サンプルの順番をシャッフルする\n",
    "            self.data = shuffle(self.data, random_state=random_state)\n",
    "        self.start_index = 0  # ポインタの位置を初期化する\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        # ポインタが最後まで到達したら初期化する\n",
    "        if self.start_index >= len(self.data):\n",
    "            self.reset()\n",
    "            raise StopIteration()\n",
    "\n",
    "        # バッチを取得\n",
    "        seqs_X, seqs_Y = zip(*self.data[self.start_index:self.start_index+self.batch_size])\n",
    "        # 入力系列seqs_Xの文章の長さ順（降順）に系列ペアをソートする\n",
    "        seq_pairs = sorted(zip(seqs_X, seqs_Y), key=lambda p: len(p[0]), reverse=True)\n",
    "        seqs_X, seqs_Y = zip(*seq_pairs)\n",
    "        # 短い系列の末尾をパディングする\n",
    "        lengths_X = [len(s) for s in seqs_X]  # 後述のEncoderのpack_padded_sequenceでも用いる\n",
    "        lengths_Y = [len(s) for s in seqs_Y]\n",
    "        max_length_X = max(lengths_X)\n",
    "        max_length_Y = max(lengths_Y)\n",
    "        padded_X = [pad_seq(s, max_length_X) for s in seqs_X]\n",
    "        padded_Y = [pad_seq(s, max_length_Y) for s in seqs_Y]\n",
    "        # tensorに変換し、転置する\n",
    "        batch_X = torch.tensor(padded_X, dtype=torch.long, device=device).transpose(0, 1)\n",
    "        batch_Y = torch.tensor(padded_Y, dtype=torch.long, device=device).transpose(0, 1)\n",
    "\n",
    "        # ポインタを更新する\n",
    "        self.start_index += self.batch_size\n",
    "\n",
    "        return batch_X, batch_Y, lengths_X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7252a7",
   "metadata": {},
   "source": [
    "# 3.モデルの構築\n",
    "EncoderとDecoderのRNNを定義します。\n",
    "### 導入：PackedSequence\n",
    "PyTorchのRNNでは、可変長の系列のバッチを効率よく計算できるように系列を表現する`PackedSequence`というクラスを用いることができます。\n",
    "\n",
    "入力バッチのテンソルをこの`PackedSequence`のインスタンスに変換してからRNNに入力することで、パディング部分の計算を省略することができるため、効率的な計算が可能になります。\n",
    "\n",
    "`PackedSequence`を作成するには、まず、系列長の異なるバッチに対してパディングを行なってください。\n",
    "\n",
    "ここで、パディングを行う前に各サンプルの系列長(`lengths`)を保存しておきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e58c76ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "各サンプルの系列長: [4, 3, 2]\n",
      "\n",
      "paddingされたテンソル:\n",
      " tensor([[1, 2, 3, 4],\n",
      "        [5, 6, 7, 0],\n",
      "        [8, 9, 0, 0]])\n",
      "padding & 転置されたテンソル:\n",
      " tensor([[1, 5, 8],\n",
      "        [2, 6, 9],\n",
      "        [3, 7, 0],\n",
      "        [4, 0, 0]])\n",
      "padding & 転置されたテンソルのサイズ:\n",
      " torch.Size([4, 3])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 系列長がそれぞれ4,3,2の3つのサンプルからなるバッチを作成\n",
    "batch = [[1,2,3,4], [5,6,7], [8,9]]\n",
    "lengths = [len(sample) for sample in batch]\n",
    "print('各サンプルの系列長:', lengths)\n",
    "print()\n",
    "\n",
    "# 最大系列長に合うように各サンプルをpadding\n",
    "_max_length = max(lengths)\n",
    "padded = torch.tensor([pad_seq(sample, _max_length) for sample in batch])\n",
    "print('paddingされたテンソル:\\n', padded)\n",
    "padded = padded.transpose(0,1) # (max_length, batch_size)に転置\n",
    "print('padding & 転置されたテンソル:\\n', padded)\n",
    "print('padding & 転置されたテンソルのサイズ:\\n', padded.size())\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152f42e0",
   "metadata": {},
   "source": [
    "次に、パディングを行ったテンソル(`padded`)と各サンプルの元々の系列長(`lengths`)を`torch.nn.utils.rnn.pack_padded_sequence`という関数に与えると、\n",
    "`data`と`batch_sizes`という要素を持った`PackedSequence`のインスタンス(`packed`)が作成できます。\n",
    "- `data`: テンソルの`PAD`以外の値のみを保有するベクトル\n",
    "- `batch_sizes`: 各時刻で計算が必要な(=`PAD`に到達していない)バッチの数を表すベクトル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f0a87019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PackedSequenceのインスタンス:\n",
      " PackedSequence(data=tensor([1, 5, 8, 2, 6, 9, 3, 7, 4]), batch_sizes=tensor([3, 3, 2, 1]), sorted_indices=None, unsorted_indices=None)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# PackedSequenceに変換（テンソルをRNNに入力する前に適用する）\n",
    "packed = pack_padded_sequence(padded, lengths=lengths) # 各サンプルの系列長も与える\n",
    "print('PackedSequenceのインスタンス:\\n', packed) # テンソルのPAD以外の値(data)と各時刻で計算が必要な(=PADに到達していない)バッチの数(batch_sizes)を有するインスタンス\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0297b150",
   "metadata": {},
   "source": [
    "こうして得られた`PackedSequence`のインスタンスをRNNに入力します。（ここでは省略）\n",
    "\n",
    "RNNから出力されたテンソルは`PackedSeauence`のインスタンスのままなので、後段の計算につなぐために`torch.nn.utils.rnn.pad_packed_sequence`の関数によって通常のテンソルに戻します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "73123de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PADを含む元のテンソル:\n",
      " tensor([[1, 5, 8],\n",
      "        [2, 6, 9],\n",
      "        [3, 7, 0],\n",
      "        [4, 0, 0]])\n",
      "各サンプルの系列長: tensor([4, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "# PackedSequenceのインスタンスをRNNに入力する（ここでは省略）\n",
    "output = packed\n",
    "\n",
    "# テンソルに戻す(RNNの出力に対して適用する)\n",
    "output, _length = pad_packed_sequence(output)  # PADを含む元のテンソルと各サンプルの系列長を返す\n",
    "print('PADを含む元のテンソル:\\n', output)\n",
    "print('各サンプルの系列長:', _length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0727a8",
   "metadata": {},
   "source": [
    "### Encoder\n",
    "今回はEncoder側でバッチを処理する際に、`pack_padded_sequence`関数によってtensorを`PackedSequence`に変換し、処理を終えた後に`pad_packed_sequence`関数によってtensorに戻すという処理を行います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "03dbda99",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        \"\"\"\n",
    "        :param input_size: int, 入力言語の語彙数\n",
    "        :param hidden_size: int, 隠れ層のユニット数\n",
    "        \"\"\"\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size, padding_idx=PAD)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, seqs, input_lengths, hidden=None):\n",
    "        \"\"\"\n",
    "        :param seqs: tensor, 入力のバッチ, size=(max_length, batch_size)\n",
    "        :param input_lengths: 入力のバッチの各サンプルの文長\n",
    "        :param hidden: tensor, 隠れ状態の初期値, Noneの場合は0で初期化される\n",
    "        :return output: tensor, Encoderの出力, size=(max_length, batch_size, hidden_size)\n",
    "        :return hidden: tensor, Encoderの隠れ状態, size=(1, batch_size, hidden_size)\n",
    "        \"\"\"\n",
    "        emb = self.embedding(seqs) # seqsはパディング済み\n",
    "        packed = pack_padded_sequence(emb, input_lengths) # PackedSequenceオブジェクトに変換\n",
    "        output, hidden = self.gru(packed, hidden)\n",
    "        output, _ = pad_packed_sequence(output)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732ca2f8",
   "metadata": {},
   "source": [
    "### Decoder\n",
    "今回はDecoder側ではパディング等行わないので、通常のtensorのままRNNに入力して問題ありません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fc3c1191",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        \"\"\"\n",
    "        :param hidden_size: int, 隠れ層のユニット数\n",
    "        :param output_size: int, 出力言語の語彙数\n",
    "        :param dropout: float, ドロップアウト率\n",
    "        \"\"\"\n",
    "        super(Decoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size, padding_idx=PAD)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, seqs, hidden):\n",
    "        \"\"\"\n",
    "        :param seqs: tensor, 入力のバッチ, size=(1, batch_size)\n",
    "        :param hidden: tensor, 隠れ状態の初期値, Noneの場合は0で初期化される\n",
    "        :return output: tensor, Decoderの出力, size=(1, batch_size, output_size)\n",
    "        :return hidden: tensor, Decoderの隠れ状態, size=(1, batch_size, hidden_size)\n",
    "        \"\"\"\n",
    "        emb = self.embedding(seqs)\n",
    "        output, hidden = self.gru(emb, hidden)\n",
    "        output = self.out(output)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9de1659",
   "metadata": {},
   "source": [
    "## EncoderDecoder\n",
    "上で定義したEncoderとDecoderを用いた、一連の処理をまとめるEncoderDecoderのクラスを定義します。\n",
    "\n",
    "ここで、Decoder側の処理で注意する点があります。\n",
    "\n",
    "RNNでは、時刻$t$の出力を時刻$t+1$の入力とすることができるが、この方法でDecoderを学習させると連鎖的に誤差が大きくなっていき、学習が不安定になったり収束が遅くなったりする問題が発生します。\n",
    "\n",
    "\n",
    "この問題への対策として**Teacher Forcing**というテクニックがあります。\n",
    "これは、訓練時にはDecoder側の入力に、ターゲット系列（参照訳）をそのまま使うというものです。\n",
    "これにより学習が安定し、収束が早くなるというメリットがありますが、逆に評価時は前の時刻にDecoderが生成したものが使われるため、学習時と分布が異なってしまうというデメリットもあります。\n",
    "\n",
    "\n",
    "Teacher Forcingの拡張として、ターゲット系列を入力とするか生成された結果を入力とするかを確率的にサンプリングする**Scheduled Sampling**という手法があります。\n",
    "\n",
    "ここではScheduled Samplingを採用し、一定の確率に基づいてターゲット系列を入力とするか生成された結果を入力とするかを切り替えられるようにクラスを定義しておきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5afaacdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderDecoder(nn.Module):\n",
    "    \"\"\"EncoderとDecoderの処理をまとめる\"\"\"\n",
    "    def __init__(self, input_size, output_size, hidden_size):\n",
    "        \"\"\"\n",
    "        :param input_size: int, 入力言語の語彙数\n",
    "        :param output_size: int, 出力言語の語彙数\n",
    "        :param hidden_size: int, 隠れ層のユニット数\n",
    "        \"\"\"\n",
    "        super(EncoderDecoder, self).__init__()\n",
    "        self.encoder = Encoder(input_size, hidden_size)\n",
    "        self.decoder = Decoder(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, batch_X, lengths_X, max_length, batch_Y=None, use_teacher_forcing=False):\n",
    "        \"\"\"\n",
    "        :param batch_X: tensor, 入力系列のバッチ, size=(max_length, batch_size)\n",
    "        :param lengths_X: list, 入力系列のバッチ内の各サンプルの文長\n",
    "        :param max_length: int, Decoderの最大文長\n",
    "        :param batch_Y: tensor, Decoderで用いるターゲット系列\n",
    "        :param use_teacher_forcing: Decoderでターゲット系列を入力とするフラグ\n",
    "        :return decoder_outputs: tensor, Decoderの出力, \n",
    "            size=(max_length, batch_size, self.decoder.output_size)\n",
    "        \"\"\"\n",
    "        # encoderに系列を入力（複数時刻をまとめて処理）\n",
    "        _, encoder_hidden = self.encoder(batch_X, lengths_X)\n",
    "        \n",
    "        _batch_size = batch_X.size(1)\n",
    "\n",
    "        # decoderの入力と隠れ層の初期状態を定義\n",
    "        decoder_input = torch.tensor([BOS] * _batch_size, dtype=torch.long, device=device) # 最初の入力にはBOSを使用する\n",
    "        decoder_input = decoder_input.unsqueeze(0)  # (1, batch_size)\n",
    "        decoder_hidden = encoder_hidden  # Encoderの最終隠れ状態を取得\n",
    "\n",
    "        # decoderの出力のホルダーを定義\n",
    "        decoder_outputs = torch.zeros(max_length, _batch_size, self.decoder.output_size, device=device) # max_length分の固定長\n",
    "\n",
    "        # 各時刻ごとに処理\n",
    "        for t in range(max_length):\n",
    "            decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden)\n",
    "            decoder_outputs[t] = decoder_output\n",
    "            # 次の時刻のdecoderの入力を決定\n",
    "            if use_teacher_forcing and batch_Y is not None:  # teacher forceの場合、ターゲット系列を用いる\n",
    "                decoder_input = batch_Y[t].unsqueeze(0)\n",
    "            else:  # teacher forceでない場合、自身の出力を用いる\n",
    "                decoder_input = decoder_output.max(-1)[1]\n",
    "                \n",
    "        return decoder_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24f8fa7",
   "metadata": {},
   "source": [
    "# 4.訓練\n",
    "### 4.1 損失関数の定義\n",
    "基本的にはクロスエントロピーを損失関数として用いますが、パディングを行うと短い系列の末尾には`<PAD>`トークンが入るため、この部分の損失を計算しないように、マスクをかけます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1b6f5977",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\takas\\anaconda3\\envs\\ml\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "mce = nn.CrossEntropyLoss(size_average=False, ignore_index=PAD) # PADを無視する\n",
    "def masked_cross_entropy(logits, target):\n",
    "    logits_flat = logits.view(-1, logits.size(-1)) # (max_seq_len * batch_size, output_size)\n",
    "    target_flat = target.view(-1) # (max_seq_len * batch_size, 1)\n",
    "    return mce(logits_flat, target_flat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c36f90a",
   "metadata": {},
   "source": [
    "### 4.2学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1567a175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ハイパーパラメータの設定\n",
    "num_epochs = 10\n",
    "batch_size = 64\n",
    "lr = 1e-3  # 学習率\n",
    "teacher_forcing_rate = 0.2  # Teacher Forcingを行う確率\n",
    "ckpt_path = 'model.pth'  # 学習済みのモデルを保存するパス\n",
    "\n",
    "model_args = {\n",
    "    'input_size': vocab_size_X,\n",
    "    'output_size': vocab_size_Y,\n",
    "    'hidden_size': 256,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3c6f124e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# データローダを定義\n",
    "train_dataloader = DataLoader(train_X, train_Y, batch_size=batch_size, shuffle=True)\n",
    "valid_dataloader = DataLoader(valid_X, valid_Y, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# モデルとOptimizerを定義\n",
    "model = EncoderDecoder(**model_args).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da47941",
   "metadata": {},
   "source": [
    "実際に損失関数を計算する関数を定義します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0e9ba3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(batch_X, batch_Y, lengths_X, model, optimizer=None, is_train=True):\n",
    "    # 損失を計算する関数\n",
    "    model.train(is_train)  # train/evalモードの切替え\n",
    "    \n",
    "    # 一定確率でTeacher Forcingを行う\n",
    "    use_teacher_forcing = is_train and (random.random() < teacher_forcing_rate)\n",
    "    max_length = batch_Y.size(0)\n",
    "    # 推論\n",
    "    pred_Y = model(batch_X, lengths_X, max_length, batch_Y, use_teacher_forcing)\n",
    "    \n",
    "    # 損失関数を計算\n",
    "    loss = masked_cross_entropy(pred_Y.contiguous(), batch_Y.contiguous())\n",
    "    \n",
    "    if is_train:  # 訓練時はパラメータを更新\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    batch_Y = batch_Y.transpose(0, 1).contiguous().data.cpu().tolist()\n",
    "    pred = pred_Y.max(dim=-1)[1].data.cpu().numpy().T.tolist()\n",
    "\n",
    "    return loss.item(), batch_Y, pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35fd5f7",
   "metadata": {},
   "source": [
    "ここで、Loss以外に、学習の進捗を確認するためにモデルの性能を評価する指標として、BLEUを計算します。\n",
    "\n",
    "BLEUは機械翻訳の分野において最も一般的な自動評価基準の一つで、予め用意した複数の参照訳と、機械翻訳モデルが出力した訳のn-gramのマッチ率に基づく指標です。\n",
    "\n",
    "NLTK (Natural Language Tool Kit) という自然言語処理で用いられるライブラリを用いて簡単に計算することができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5af33b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_bleu(refs, hyps):\n",
    "    \"\"\"\n",
    "    BLEUスコアを計算する関数\n",
    "    :param refs: list, 参照訳。単語のリストのリスト (例： [['I', 'have', 'a', 'pen'], ...])\n",
    "    :param hyps: list, モデルの生成した訳。単語のリストのリスト (例： ['I', 'have', 'a', 'pen'])\n",
    "    :return: float, BLEUスコア(0~100)\n",
    "    \"\"\"\n",
    "    refs = [[ref[:ref.index(EOS)]] for ref in refs] # EOSは評価しないで良いので切り捨てる, refsのほうは複数なのでlistが一個多くかかっている\n",
    "    hyps = [hyp[:hyp.index(EOS)] if EOS in hyp else hyp for hyp in hyps]\n",
    "    return 100 * bleu_score.corpus_bleu(refs, hyps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327b1919",
   "metadata": {},
   "source": [
    "それではモデルの訓練を行います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4a3a9fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train_loss: 52.14  train_bleu: 3.47  valid_loss: 49.35  valid_bleu: 4.60\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 2: train_loss: 44.78  train_bleu: 7.34  valid_loss: 44.96  valid_bleu: 7.35\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 3: train_loss: 40.56  train_bleu: 10.93  valid_loss: 42.49  valid_bleu: 9.54\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 4: train_loss: 37.79  train_bleu: 13.56  valid_loss: 41.29  valid_bleu: 12.51\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 5: train_loss: 35.26  train_bleu: 16.38  valid_loss: 40.34  valid_bleu: 13.75\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 6: train_loss: 33.46  train_bleu: 18.62  valid_loss: 40.01  valid_bleu: 14.89\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 7: train_loss: 31.84  train_bleu: 20.59  valid_loss: 39.88  valid_bleu: 14.34\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 8: train_loss: 30.81  train_bleu: 22.01  valid_loss: 40.24  valid_bleu: 16.22\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 9: train_loss: 29.19  train_bleu: 24.23  valid_loss: 40.80  valid_bleu: 18.38\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 10: train_loss: 28.32  train_bleu: 25.83  valid_loss: 40.72  valid_bleu: 17.64\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 訓練\n",
    "best_valid_bleu = 0.\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    train_loss = 0.\n",
    "    train_refs = []\n",
    "    train_hyps = []\n",
    "    valid_loss = 0.\n",
    "    valid_refs = []\n",
    "    valid_hyps = []\n",
    "    # train\n",
    "    for batch in train_dataloader:\n",
    "        batch_X, batch_Y, lengths_X = batch\n",
    "        loss, gold, pred = compute_loss(\n",
    "            batch_X, batch_Y, lengths_X, model, optimizer, \n",
    "            is_train=True\n",
    "            )\n",
    "        train_loss += loss\n",
    "        train_refs += gold\n",
    "        train_hyps += pred\n",
    "    # valid\n",
    "    for batch in valid_dataloader:\n",
    "        batch_X, batch_Y, lengths_X = batch\n",
    "        loss, gold, pred = compute_loss(\n",
    "            batch_X, batch_Y, lengths_X, model, \n",
    "            is_train=False\n",
    "            )\n",
    "        valid_loss += loss\n",
    "        valid_refs += gold\n",
    "        valid_hyps += pred\n",
    "    # 損失をサンプル数で割って正規化\n",
    "    train_loss = np.sum(train_loss) / len(train_dataloader.data)\n",
    "    valid_loss = np.sum(valid_loss) / len(valid_dataloader.data)\n",
    "    # BLEUを計算\n",
    "    train_bleu = calc_bleu(train_refs, train_hyps)\n",
    "    valid_bleu = calc_bleu(valid_refs, valid_hyps)\n",
    "\n",
    "    # validationデータでBLEUが改善した場合にはモデルを保存\n",
    "    if valid_bleu > best_valid_bleu:\n",
    "        ckpt = model.to('cpu').state_dict()\n",
    "        torch.save(ckpt, ckpt_path)\n",
    "        best_valid_bleu = valid_bleu\n",
    "\n",
    "    print('Epoch {}: train_loss: {:5.2f}  train_bleu: {:2.2f}  valid_loss: {:5.2f}  valid_bleu: {:2.2f}'.format(\n",
    "            epoch, train_loss, train_bleu, valid_loss, valid_bleu))\n",
    "        \n",
    "    print('-'*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a758e9",
   "metadata": {},
   "source": [
    "# 5.評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bc0aab11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EncoderDecoder(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(3725, 256, padding_idx=0)\n",
       "    (gru): GRU(256, 256)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(4405, 256, padding_idx=0)\n",
       "    (gru): GRU(256, 256)\n",
       "    (out): Linear(in_features=256, out_features=4405, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 学習済みモデルの読み込み\n",
    "ckpt = torch.load(ckpt_path ,map_location=torch.device('cpu')) # cpuで処理する場合はmap_locationで指定する必要があります。\n",
    "model.load_state_dict(ckpt)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "18272eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ids_to_sentence(vocab, ids):\n",
    "    # IDのリストを単語のリストに変換する\n",
    "    return [vocab.id2word[_id] for _id in ids]\n",
    "\n",
    "def trim_eos(ids):\n",
    "    # IDのリストからEOS以降の単語を除外する\n",
    "    if EOS in ids:\n",
    "        return ids[:ids.index(EOS)]\n",
    "    else:\n",
    "        return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e81e0eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# テストデータの読み込み\n",
    "test_X = load_data('./data/dev.en')\n",
    "test_Y = load_data('./data/dev.ja')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d9407c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = [sentence_to_ids(vocab_X, sentence) for sentence in test_X]\n",
    "test_Y = [sentence_to_ids(vocab_Y, sentence) for sentence in test_Y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7286183b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(test_X, test_Y, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "43f709c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src: show your own business .\n",
      "tgt: 自分 の 事 を しろ 。\n",
      "out: 自分 の 自分 を し て て 。 。\n",
      "without trim: 自分 の 自分 を し て て 。 。 </S> </S> </S> </S> </S> </S> </S> </S> </S> </S> </S>\n"
     ]
    }
   ],
   "source": [
    "# 生成\n",
    "batch_X, batch_Y, lengths_X = next(test_dataloader)\n",
    "sentence_X = ' '.join(ids_to_sentence(vocab_X, batch_X.data.cpu().numpy()[:-1, 0]))\n",
    "sentence_Y = ' '.join(ids_to_sentence(vocab_Y, batch_Y.data.cpu().numpy()[:-1, 0]))\n",
    "print('src: {}'.format(sentence_X))\n",
    "print('tgt: {}'.format(sentence_Y))\n",
    "\n",
    "output = model(batch_X, lengths_X, max_length=20)\n",
    "output = output.max(dim=-1)[1].view(-1).data.cpu().tolist()\n",
    "output_sentence = ' '.join(ids_to_sentence(vocab_Y, trim_eos(output)))\n",
    "output_sentence_without_trim = ' '.join(ids_to_sentence(vocab_Y, output))\n",
    "print('out: {}'.format(output_sentence))\n",
    "print('without trim: {}'.format(output_sentence_without_trim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "832ca957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.6720646449301\n"
     ]
    }
   ],
   "source": [
    "# BLEUの計算\n",
    "test_dataloader = DataLoader(test_X, test_Y, batch_size=1, shuffle=False)\n",
    "refs_list = []\n",
    "hyp_list = []\n",
    "\n",
    "for batch in test_dataloader:\n",
    "    batch_X, batch_Y, lengths_X = batch\n",
    "    pred_Y = model(batch_X, lengths_X, max_length=20)\n",
    "    pred = pred_Y.max(dim=-1)[1].view(-1).data.cpu().tolist()\n",
    "    refs = batch_Y.view(-1).data.cpu().tolist()\n",
    "    refs_list.append(refs)\n",
    "    hyp_list.append(pred)\n",
    "bleu = calc_bleu(refs_list, hyp_list)\n",
    "print(bleu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9317fa0c",
   "metadata": {},
   "source": [
    "### Beam Search\n",
    "テストデータに対して新たな文を生成する際、これまでは各時刻で最も確率の高い単語を正解として採用し、次のステップでの入力として使っていました。\n",
    "ただ、本当にやりたいのは、文全体の尤度が最も高くなるような文を生成することです。そのため、ただ近視眼的に確率の高い単語を採用していくより、もう少し大局的に評価していく必要があります。\n",
    "\n",
    "Beam Searchでは、各時刻において一定の数$K$のそれまでのスコア(対数尤度など)の高い文を保持しながら選択を行っていきます。  \n",
    "\n",
    "\n",
    "図はSlack上のものを参照してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "51c3e780",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BeamEncoderDecoder(EncoderDecoder):\n",
    "    \"\"\"\n",
    "    Beam Searchでdecodeを行うためのクラス\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, output_size, hidden_size, beam_size=4):\n",
    "        \"\"\"\n",
    "        :param input_size: int, 入力言語の語彙数\n",
    "        :param output_size: int, 出力言語の語彙数\n",
    "        :param hidden_size: int, 隠れ層のユニット数\n",
    "        :param beam_size: int, ビーム数\n",
    "        \"\"\"\n",
    "        super(BeamEncoderDecoder, self).__init__(input_size, output_size, hidden_size)\n",
    "        self.beam_size = beam_size\n",
    "\n",
    "    def forward(self, batch_X, lengths_X, max_length):\n",
    "        \"\"\"\n",
    "        :param batch_X: tensor, 入力系列のバッチ, size=(max_length, batch_size)\n",
    "        :param lengths_X: list, 入力系列のバッチ内の各サンプルの文長\n",
    "        :param max_length: int, Decoderの最大文長\n",
    "        :return decoder_outputs: list, 各ビームのDecoderの出力\n",
    "        :return finished_scores: list of float, 各ビームのスコア\n",
    "        \"\"\"\n",
    "        _, encoder_hidden = self.encoder(batch_X, lengths_X)\n",
    "\n",
    "        # decoderの入力と隠れ層の初期状態を定義\n",
    "        decoder_input = torch.tensor([BOS] * self.beam_size, dtype=torch.long, device=device)\n",
    "        decoder_input = decoder_input.unsqueeze(0)  # (1, batch_size)\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        # beam_sizeの数だけrepeatする\n",
    "        decoder_input = decoder_input.expand(1, beam_size)\n",
    "        decoder_hidden = decoder_hidden.expand(1, beam_size, -1).contiguous()\n",
    "\n",
    "        k = beam_size\n",
    "        finished_beams = []\n",
    "        finished_scores = []\n",
    "        prev_probs = torch.zeros(beam_size, 1, dtype=torch.float, device=device)  # 前の時刻の各ビームの対数尤度を保持しておく\n",
    "        output_size = self.decoder.output_size\n",
    "\n",
    "        # 各時刻ごとに処理\n",
    "        for t in range(max_length):\n",
    "            # decoder_input: (1, k)\n",
    "            decoder_output, decoder_hidden = self.decoder(decoder_input[-1:], decoder_hidden)\n",
    "            # decoder_output: (1, k, output_size)\n",
    "            # decoder_hidden: (1, k, hidden_size)\n",
    "            decoder_output_t = decoder_output[-1]  # (k, output_size)\n",
    "            log_probs = prev_probs + F.log_softmax(decoder_output_t, dim=-1)  # (k, output_size)\n",
    "            scores = log_probs  # 対数尤度をスコアとする\n",
    "\n",
    "            # スコアの高いビームとその単語を取得\n",
    "            flat_scores = scores.view(-1)  # (k*output_size,)\n",
    "            if t == 0:\n",
    "                flat_scores = flat_scores[:output_size]  # t=0のときは後半の同じ値の繰り返しを除外\n",
    "            top_vs, top_is = flat_scores.data.topk(k)\n",
    "            beam_indices = top_is / output_size  # (k,)\n",
    "            word_indices = top_is % output_size  # (k,)\n",
    "            \n",
    "            # ビームを更新する\n",
    "            _next_beam_indices = []\n",
    "            _next_word_indices = []\n",
    "            for b, w in zip(beam_indices, word_indices):\n",
    "                if w.item() == EOS:  # EOSに到達した場合はそのビームは更新して終了\n",
    "                    k -= 1\n",
    "                    beam = torch.cat([decoder_input.t()[b], w.view(1,)])  # (t+2,)\n",
    "                    score = scores[b, w].item()\n",
    "                    finished_beams.append(beam)\n",
    "                    finished_scores.append(score)\n",
    "                else:   # それ以外の場合はビームを更新\n",
    "                    _next_beam_indices.append(b)\n",
    "                    _next_word_indices.append(w)\n",
    "            if k == 0:\n",
    "                break\n",
    "\n",
    "            # tensorｎに変換\n",
    "            next_beam_indices = torch.tensor(_next_beam_indices, device=device)\n",
    "            next_word_indices = torch.tensor(_next_word_indices, device=device)\n",
    "\n",
    "            # 次の時刻のDecoderの入力を更新\n",
    "            decoder_input = torch.index_select(\n",
    "                decoder_input, dim=-1, index=next_beam_indices)\n",
    "            decoder_input = torch.cat(\n",
    "                [decoder_input, next_word_indices.unsqueeze(0)], dim=0)\n",
    "    \n",
    "            # 次の時刻のDecoderの隠れ層を更新\n",
    "            decoder_hidden = torch.index_select(\n",
    "                decoder_hidden, dim=1, index=next_beam_indices)\n",
    "\n",
    "            # 各ビームの対数尤度を更新\n",
    "            flat_probs = log_probs.view(-1)  # (k*output_size,)\n",
    "            next_indices = (next_beam_indices + 1) * next_word_indices\n",
    "            prev_probs = torch.index_select(\n",
    "                flat_probs, dim=0, index=next_indices).unsqueeze(1)  # (k, 1)\n",
    "\n",
    "        # すべてのビームが完了したらデータを整形\n",
    "        decoder_outputs = [[idx.item() for idx in beam[1:-1]] for beam in finished_beams]\n",
    "        \n",
    "        return decoder_outputs, finished_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "69038dd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BeamEncoderDecoder(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(3725, 256, padding_idx=0)\n",
       "    (gru): GRU(256, 256)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(4405, 256, padding_idx=0)\n",
       "    (gru): GRU(256, 256)\n",
       "    (out): Linear(in_features=256, out_features=4405, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 学習済みモデルの読み込み\n",
    "beam_size = 3\n",
    "beam_model = BeamEncoderDecoder(**model_args, beam_size=beam_size).to(device)\n",
    "beam_model.load_state_dict(ckpt)\n",
    "beam_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5d04c7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(test_X, test_Y, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a90f944d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src: show your own business .\n",
      "tgt: 自分 の 事 を しろ 。\n",
      "out: 自分 の 自分 を し て て 。 。\n"
     ]
    }
   ],
   "source": [
    "# 生成\n",
    "batch_X, batch_Y, lengths_X = next(test_dataloader)\n",
    "sentence_X = ' '.join(ids_to_sentence(vocab_X, batch_X.data.cpu().numpy()[:-1, 0]))\n",
    "sentence_Y = ' '.join(ids_to_sentence(vocab_Y, batch_Y.data.cpu().numpy()[:-1, 0]))\n",
    "print('src: {}'.format(sentence_X))\n",
    "print('tgt: {}'.format(sentence_Y))\n",
    "\n",
    "# 普通のdecode\n",
    "output = model(batch_X, lengths_X, max_length=20)\n",
    "output = output.max(dim=-1)[1].view(-1).data.cpu().tolist()\n",
    "output_sentence = ' '.join(ids_to_sentence(vocab_Y, trim_eos(output)))\n",
    "print('out: {}'.format(output_sentence))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d4b9cc08",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "index_select(): Expected dtype int32 or int64 for index",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16100/2011020290.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# beam decode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbeam_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlengths_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# scoreの良い順にソート\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ml\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16100/762265759.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, batch_X, lengths_X, max_length)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m             \u001b[1;31m# 次の時刻のDecoderの入力を更新\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m             decoder_input = torch.index_select(\n\u001b[0m\u001b[0;32m     80\u001b[0m                 decoder_input, dim=-1, index=next_beam_indices)\n\u001b[0;32m     81\u001b[0m             decoder_input = torch.cat(\n",
      "\u001b[1;31mRuntimeError\u001b[0m: index_select(): Expected dtype int32 or int64 for index"
     ]
    }
   ],
   "source": [
    "# beam decode\n",
    "outputs, scores = beam_model(batch_X, lengths_X, max_length=20)\n",
    "\n",
    "# scoreの良い順にソート\n",
    "outputs, scores = zip(*sorted(zip(outputs, scores), key=lambda x: -x[1]))\n",
    "for o, output in enumerate(outputs):\n",
    "    output_sentence = ' '.join(ids_to_sentence(vocab_Y, output))\n",
    "    print('out{}: {}'.format(o+1, output_sentence))    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d881e6c",
   "metadata": {},
   "source": [
    "# 参考文献\n",
    "- [Practical PyTorch: Translation with a Sequence to Sequence Network and Attention](https://github.com/spro/practical-pytorch/blob/master/seq2seq-translation/seq2seq-translation-batched.ipynb)\n",
    "- [Translation with a Sequence to Sequence Network and Attention](https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html#sphx-glr-intermediate-seq2seq-translation-tutorial-py)\n",
    "- [Encoder\\-decoderモデルとTeacher Forcing，Scheduled Sampling，Professor Forcing](http://satopirka.com/2018/02/encoder-decoder%E3%83%A2%E3%83%87%E3%83%AB%E3%81%A8teacher-forcingscheduled-samplingprofessor-forcing/)\n",
    "- [Sequence\\-to\\-Sequence Learning as Beam\\-Search Optimization](https://arxiv.org/abs/1606.02960)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876420ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d95b0c92",
   "metadata": {},
   "source": [
    "## ニューラル機械翻訳の問題点：長さに弱い\n",
    "- 翻訳元の文の内容をひとつのベクトルで表現 \n",
    "- 文長が長くなると表現力が足りなくなる \n",
    "- 文長と翻訳精度の関係性\n",
    "\n",
    "## Attention (注意機構) \n",
    "- 翻訳先の各単語を選択する際に、翻訳元の文中の各単語の隠れ状態を利用\n",
    "\n",
    "#### 翻訳元の各単語の隠れ状態の加重平均\n",
    "\n",
    "\\begin{aligned}\n",
    "C_i = \\sum_{j=1}^{T_x} \\alpha_{ij}h_j\n",
    "\\end{aligned}\n",
    "\n",
    "#### 重み(全て足すと１) 重みはFFNNで求める\n",
    "\n",
    "\\begin{aligned}\n",
    "\\alpha_{ij} &= \\frac{exp(e_{ij})}{\\sum_{k=1}^{T_x} exp(e_{ik})} \\\\[10px]\n",
    "e_{ik} &= a(s_{i-1} , h_j)\n",
    "\\end{aligned}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f8ab39",
   "metadata": {},
   "source": [
    "### Attentionは何をしているのか\n",
    "query(検索クエリ)に一致するkeyを索引し、対応するvalueを取り出す操作であると見做すことができる。これは辞書オブジェクトの機能と同じである。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f5533231",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(\"./Section5_Attention1.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e377acb7",
   "metadata": {},
   "source": [
    "## Attention is all you need\n",
    "- 2017年6月に登場 \n",
    "- RNNを使わない \n",
    " - 必要なのはAttentionだけ \n",
    "- 当時のSOTAをはるかに少ない計算量で実現 \n",
    " - 英仏 (3600万文) の学習を8GPUで3.5日で完了"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7487b68c",
   "metadata": {},
   "source": [
    "## 注意機構には二種類ある\n",
    "\n",
    "### Source Target-Attention(ソースターゲット注意機構)\n",
    "情報が来る場所と狙う場所が分かれている。 \\\n",
    "受け取った情報に対して、狙うべき情報が近い場合に注目する。\n",
    "\n",
    "### Self-Attention(自己注意機構)\n",
    "Q,K,Vがすべて同じ場所から来る。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e04f0b",
   "metadata": {},
   "source": [
    "## Transformer-Encoder\n",
    "\n",
    "### Scaled dot product attention\n",
    "\n",
    "\n",
    "### Position-Wise Feed-Forward Networks\n",
    "- 位置情報を保持したまま順伝播させる\n",
    "\n",
    "### Multi-Head attention\n",
    "- 全単語に関するAttentionをまとめて計算する\n",
    "\n",
    "#### 重みパラメタの異なる８個のヘッドを使用\n",
    "- ８個のScaled Dot-Product Attentionの出力をConcat \n",
    "- それぞれのヘッドが異なる種類の情報を収集"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708fcdc0",
   "metadata": {},
   "source": [
    "## Decoder\n",
    "- Encoderと同じく6層 \n",
    " - 各層で二種類の注意機構 \n",
    " - 注意機構の仕組みはEncoderとほぼ同じ \n",
    "- 自己注意機構 \n",
    " - 生成単語列の情報を収集 \n",
    " - 直下の層の出力へのアテンション \n",
    " - 未来の情報を見ないようにマスク \n",
    "- Encoder-Decoder attention \n",
    " - 入力文の情報を収集 \n",
    " - Encoderの出力へのアテンション\n",
    " \n",
    "### Add (Residual Connection) \n",
    "- 入出力の差分を学習させる \n",
    "- 実装上は出力に入力をそのまま加算するだけ \n",
    "- 効果：学習・テストエラーの低減 \n",
    "\n",
    "### Norm (Layer Normalization) \n",
    "- 各層においてバイアスを除く活性化関数への入力を平均０、分散１に正則化 \n",
    "- 効果：学習の高速化\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a944a1d9",
   "metadata": {},
   "source": [
    "## Position Encoding\n",
    "RNNを用いないので単語列の語順情報を追加する必要がある"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406cd810",
   "metadata": {},
   "source": [
    "#### ゼロから作るディープラーニング②　8.1　Attentionの仕組み\n",
    "これまで見てきたseq2seqをさらに強力にする注意機構（Attention mechanism）というアイデアを紹介します。このAttentionというメカニズムによって、seq2seqは私たち人間と同じように、必要な情報だけに「注意」を向けさせることができます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea39143",
   "metadata": {},
   "source": [
    "# 演習 Transformerモデル\n",
    "TransformerはRNNやCNNを使用せず、Attentionのみを用いるSeq2Seqモデルです。\n",
    "\n",
    "並列計算が可能なためRNNに比べて計算が高速な上、Self-Attentionと呼ばれる機構を用いることにより、局所的な位置しか参照できないCNNと異なり、系列内の任意の位置の情報を参照することを可能にしています。\n",
    "\n",
    "その他にもいくつかの工夫が加えられており、翻訳に限らない自然言語処理のあらゆるタスクで圧倒的な性能を示すことが知られています。\n",
    "\n",
    "原論文：[Attention is All You Need](https://arxiv.org/abs/1706.03762)\n",
    "\n",
    "参考実装：https://github.com/jadore801120/attention-is-all-you-need-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "514e81b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from nltk import bleu_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from utils import Vocab\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "torch.manual_seed(1)\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7430e01a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8.2+cpu\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1c32b32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD = 0\n",
    "UNK = 1\n",
    "BOS = 2\n",
    "EOS = 3\n",
    "\n",
    "PAD_TOKEN = '<PAD>'\n",
    "UNK_TOKEN = '<UNK>'\n",
    "BOS_TOKEN = '<S>'\n",
    "EOS_TOKEN = '</S>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9c8cf522",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    \"\"\"\n",
    "    テキストファイルからデータを読み込む\n",
    "    :param file_path: str, テキストファイルのパス\n",
    "    :return data: list, 文章（単語のリスト）のリスト\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    for line in open(file_path, encoding='utf-8'):\n",
    "        words = line.strip().split()  # スペースで単語を分割\n",
    "        data.append(words)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2afd59fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = load_data('./data/train.en')\n",
    "train_Y = load_data('./data/train.ja')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5466946c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練データと検証データに分割\n",
    "train_X, valid_X, train_Y, valid_Y = train_test_split(train_X, train_Y, test_size=0.2, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6edf485f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_X: [['where', 'shall', 'we', 'eat', 'tonight', '?'], ['i', 'made', 'a', 'big', 'mistake', 'in', 'choosing', 'my', 'wife', '.'], ['i', \"'ll\", 'have', 'to', 'think', 'about', 'it', '.'], ['it', 'is', 'called', 'a', 'lily', '.'], ['could', 'you', 'lend', 'me', 'some', 'money', 'until', 'this', 'weekend', '?']]\n",
      "train_Y: [['今夜', 'は', 'どこ', 'で', '食事', 'を', 'し', 'よ', 'う', 'か', '。'], ['僕', 'は', '妻', 'を', '選', 'ぶ', 'の', 'に', '大変', 'な', '間違い', 'を', 'し', 'た', '。'], ['考え', 'と', 'く', 'よ', '。'], ['ｌｉｌｙ', 'と', '呼', 'ば', 'れ', 'て', 'い', 'ま', 'す', '。'], ['今週末', 'まで', 'いくら', 'か', '金', 'を', '貸', 'し', 'て', 'くれ', 'ま', 'せ', 'ん', 'か', '。']]\n"
     ]
    }
   ],
   "source": [
    "# データセットの中身を確認\n",
    "print('train_X:', train_X[:5])\n",
    "print('train_Y:', train_Y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c70b7b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_COUNT = 2  # 語彙に含める単語の最低出現回数\n",
    "\n",
    "word2id = {\n",
    "    PAD_TOKEN: PAD,\n",
    "    BOS_TOKEN: BOS,\n",
    "    EOS_TOKEN: EOS,\n",
    "    UNK_TOKEN: UNK,\n",
    "    }\n",
    "\n",
    "vocab_X = Vocab(word2id=word2id)\n",
    "vocab_Y = Vocab(word2id=word2id)\n",
    "vocab_X.build_vocab(train_X, min_count=MIN_COUNT)\n",
    "vocab_Y.build_vocab(train_Y, min_count=MIN_COUNT)\n",
    "\n",
    "vocab_size_X = len(vocab_X.id2word)\n",
    "vocab_size_Y = len(vocab_Y.id2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a3a2020c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_to_ids(vocab, sentence):\n",
    "    \"\"\"\n",
    "    単語のリストをインデックスのリストに変換する\n",
    "    :param vocab: Vocabのインスタンス\n",
    "    :param sentence: list of str\n",
    "    :return indices: list of int\n",
    "    \"\"\"\n",
    "    ids = [vocab.word2id.get(word, UNK) for word in sentence]\n",
    "    ids = [BOS] + ids + [EOS]  # EOSを末尾に加える\n",
    "    return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e47c302b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = [sentence_to_ids(vocab_X, sentence) for sentence in train_X]\n",
    "train_Y = [sentence_to_ids(vocab_Y, sentence) for sentence in train_Y]\n",
    "valid_X = [sentence_to_ids(vocab_X, sentence) for sentence in valid_X]\n",
    "valid_Y = [sentence_to_ids(vocab_Y, sentence) for sentence in valid_Y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fa5226f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader(object):\n",
    "    def __init__(self, src_insts, tgt_insts, batch_size, shuffle=True):\n",
    "        \"\"\"\n",
    "        :param src_insts: list, 入力言語の文章（単語IDのリスト）のリスト\n",
    "        :param tgt_insts: list, 出力言語の文章（単語IDのリスト）のリスト\n",
    "        :param batch_size: int, バッチサイズ\n",
    "        :param shuffle: bool, サンプルの順番をシャッフルするか否か\n",
    "        \"\"\"\n",
    "        self.data = list(zip(src_insts, tgt_insts))\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.start_index = 0\n",
    "        \n",
    "        self.reset()\n",
    "    \n",
    "    def reset(self):\n",
    "        if self.shuffle:\n",
    "            self.data = shuffle(self.data, random_state=random_state)\n",
    "        self.start_index = 0\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "\n",
    "        def preprocess_seqs(seqs):\n",
    "            # パディング\n",
    "            max_length = max([len(s) for s in seqs])\n",
    "            data = [s + [PAD] * (max_length - len(s)) for s in seqs]\n",
    "            # 単語の位置を表現するベクトルを作成\n",
    "            positions = [[pos+1 if w != PAD else 0 for pos, w in enumerate(seq)] for seq in data]\n",
    "            # テンソルに変換\n",
    "            data_tensor = torch.tensor(data, dtype=torch.long, device=device)\n",
    "            position_tensor = torch.tensor(positions, dtype=torch.long, device=device)\n",
    "            return data_tensor, position_tensor            \n",
    "\n",
    "        # ポインタが最後まで到達したら初期化する\n",
    "        if self.start_index >= len(self.data):\n",
    "            self.reset()\n",
    "            raise StopIteration()\n",
    "\n",
    "        # バッチを取得して前処理\n",
    "        src_seqs, tgt_seqs = zip(*self.data[self.start_index:self.start_index+self.batch_size])\n",
    "        src_data, src_pos = preprocess_seqs(src_seqs)\n",
    "        tgt_data, tgt_pos = preprocess_seqs(tgt_seqs)\n",
    "\n",
    "        # ポインタを更新する\n",
    "        self.start_index += self.batch_size\n",
    "\n",
    "        return (src_data, src_pos), (tgt_data, tgt_pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60ff676",
   "metadata": {},
   "source": [
    "## 2.各モジュールの定義\n",
    "TransformerのモデルもEncoder-Decoderモデルの構造になっています。\n",
    "EncoderとDecoderは\n",
    "- Positional Encoding: 入出力の単語のEmbedding時に単語の位置情報を埋め込む\n",
    "- Scaled Dot-Product Attention: 内積でAttentionを計算し、スケーリングを行う\n",
    "- Multi-head Attention: Scaled Dot-Product Attentionを複数のヘッドで並列化する\n",
    "- Position-Wise Feed Forward Network: 単語列の位置ごとに独立して処理を行う\n",
    "など、いくつかのモジュールから構成されているため、それぞれのモジュールを個別に定義していきます。\n",
    "\n",
    "### ① Position Encoding\n",
    "Transformerは系列の処理にRNNを使用しないので、そのままでは単語列の語順を考慮することができません。\n",
    "\n",
    "そのため、入力系列の埋め込み行列に単語の位置情報を埋め込むPosition Encodingを加算します。\n",
    "\n",
    "Positional Encodingの行列$PE$の各成分は次式で表されます。\n",
    "$PE_{(pos, 2i)} = \\sin(pos/10000^{2i/d_{model}})$\n",
    "\n",
    "$PE_{(pos, 2i+1)} = \\cos(pos/10000^{2i/d_{model}})$\n",
    "ここで$pos$は単語の位置を、$i$は成分の次元を表しています。\n",
    "\n",
    "Positional Encodingの各成分は、波長が$2\\pi$から$10000*2\\pi$に幾何学的に伸びる正弦波に対応します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3b60bde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def position_encoding_init(n_position, d_pos_vec):\n",
    "    \"\"\"\n",
    "    Positional Encodingのための行列の初期化を行う\n",
    "    :param n_position: int, 系列長\n",
    "    :param d_pos_vec: int, 隠れ層の次元数\n",
    "    :return torch.tensor, size=(n_position, d_pos_vec)\n",
    "    \"\"\"\n",
    "    # PADがある単語の位置はpos=0にしておき、position_encも0にする\n",
    "    position_enc = np.array([\n",
    "        [pos / np.power(10000, 2 * (j // 2) / d_pos_vec) for j in range(d_pos_vec)]\n",
    "        if pos != 0 else np.zeros(d_pos_vec) for pos in range(n_position)])\n",
    "    position_enc[1:, 0::2] = np.sin(position_enc[1:, 0::2])  # dim 2i\n",
    "    position_enc[1:, 1::2] = np.cos(position_enc[1:, 1::2])  # dim 2i+1\n",
    "    return torch.tensor(position_enc, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c187d7b",
   "metadata": {},
   "source": [
    "ちなみに、Position Encodingを可視化すると以下のようになります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "74d0f7eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pe = position_encoding_init(50, 256).numpy()\n",
    "plt.figure(figsize=(16,8))\n",
    "sns.heatmap(pe, cmap='Blues')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa31f98",
   "metadata": {},
   "source": [
    "縦軸が単語の位置を、横軸が成分の次元を表しており、濃淡が加算される値です。\n",
    "\n",
    "ここでは最大系列長を50、隠れ層の次元数を256としました。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62cd494a",
   "metadata": {},
   "source": [
    "### ② Multihead Attention\n",
    "ソース・ターゲット注意機構と自己注意機構\n",
    "Attentionは一般に、queryベクトルとkeyベクトルの類似度を求めて、その正規化した重みをvalueベクトルに適用して値を取り出す処理を行います。\n",
    "\n",
    "一般的な翻訳モデルで用いられるAttentionはソース・ターゲット注意機構と呼ばれ、この場合queryはDecoderの隠れ状態(Target)、keyはEncoderの隠れ状態(Source)、valueもEncoderの隠れ状態(Source)で表現されるのが一般的です。モデル全体の図では、右側のDecoderブロックの中央にあるAttentionがこれに相当します。\n",
    "\n",
    "Transformerでは、このソース・ターゲット注意機構に加えて、query,key,valueを同じ系列内で定義する自己注意機構を用います。これにより、ある単語位置の出力を求める際にあらゆる位置を参照できるため、局所的な位置しか参照できない畳み込み層よりも良い性能を発揮できると言われています。モデル全体の図では、左側のEncoderブロックと右側のDecoderブロックの下部にあるAttentionがこれに当たります。\n",
    "\n",
    "Transformerでは、Scaled Dot-Product Attentionと呼ばれるAttentionを、複数のヘッドで並列に扱うMulti-Head Attentionによって、Source-Target-AttentionとSelf-Attentionを実現します。\n",
    "\n",
    "#### Scaled Dot-Product Attention\n",
    "Attentionには、注意の重みを隠れ層 1 つのフィードフォワードネットワークで求めるAdditive Attentionと、注意の重みを内積で求めるDot-Product Attentionが存在します。  一般に、Dot-Product Attentionのほうがパラメータが少なく高速であり、Transformerでもこちらを使います。\n",
    "\n",
    "\n",
    "Tranformerではさらなる工夫として、query($Q$)とkey($K$)の内積をスケーリング因子 $\\sqrt{d_k}$ で除算します。\n",
    "\n",
    "$Attention(Q, K, V) = softmax(\\frac{QK^T}{\\sqrt{d_k}})V$ \n",
    "\n",
    "\n",
    "これは、$d_k$（keyベクトルの次元数）が大きい場合に内積が大きくなりすぎて逆伝播のsoftmaxの勾配が極端に小さくなることを防ぐ役割を果たします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c6a07c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaledDotProductAttention(nn.Module):\n",
    "    \n",
    "    def __init__(self, d_model, attn_dropout=0.1):\n",
    "        \"\"\"\n",
    "        :param d_model: int, 隠れ層の次元数\n",
    "        :param attn_dropout: float, ドロップアウト率\n",
    "        \"\"\"\n",
    "        super(ScaledDotProductAttention, self).__init__()\n",
    "        self.temper = np.power(d_model, 0.5)  # スケーリング因子\n",
    "        self.dropout = nn.Dropout(attn_dropout)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, q, k, v, attn_mask):\n",
    "        \"\"\"\n",
    "        :param q: torch.tensor, queryベクトル, \n",
    "            size=(n_head*batch_size, len_q, d_model/n_head)\n",
    "        :param k: torch.tensor, key, \n",
    "            size=(n_head*batch_size, len_k, d_model/n_head)\n",
    "        :param v: torch.tensor, valueベクトル, \n",
    "            size=(n_head*batch_size, len_v, d_model/n_head)\n",
    "        :param attn_mask: torch.tensor, Attentionに適用するマスク, \n",
    "            size=(n_head*batch_size, len_q, len_k)\n",
    "        :return output: 出力ベクトル, \n",
    "            size=(n_head*batch_size, len_q, d_model/n_head)\n",
    "        :return attn: Attention\n",
    "            size=(n_head*batch_size, len_q, len_k)\n",
    "        \"\"\"\n",
    "        # QとKの内積でAttentionの重みを求め、スケーリングする\n",
    "        attn = torch.bmm(q, k.transpose(1, 2)) / self.temper  # (n_head*batch_size, len_q, len_k)\n",
    "        # Attentionをかけたくない部分がある場合は、その部分を負の無限大に飛ばしてSoftmaxの値が0になるようにする\n",
    "        attn.data.masked_fill_(attn_mask, -float('inf'))\n",
    "        \n",
    "        attn = self.softmax(attn)\n",
    "        attn = self.dropout(attn)\n",
    "        output = torch.bmm(attn, v)\n",
    "\n",
    "        return output, attn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c330106",
   "metadata": {},
   "source": [
    "#### Multi-Head Attention\n",
    "TransformerではAttentionを複数のヘッドで並列に行うMulti-Head Attentionを採用しています。\n",
    "\n",
    "複数のヘッドでAttentionを行うことにより、各ヘッドが異なる部分空間を処理でき、精度が向上するとされています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6caec236",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, n_head, d_model, d_k, d_v, dropout=0.1):\n",
    "        \"\"\"\n",
    "        :param n_head: int, ヘッド数\n",
    "        :param d_model: int, 隠れ層の次元数\n",
    "        :param d_k: int, keyベクトルの次元数\n",
    "        :param d_v: int, valueベクトルの次元数\n",
    "        :param dropout: float, ドロップアウト率\n",
    "        \"\"\"\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "\n",
    "        self.n_head = n_head\n",
    "        self.d_k = d_k\n",
    "        self.d_v = d_v\n",
    "\n",
    "        # 各ヘッドごとに異なる重みで線形変換を行うための重み\n",
    "        # nn.Parameterを使うことで、Moduleのパラメータとして登録できる. TFでは更新が必要な変数はtf.Variableでラップするのでわかりやすい\n",
    "        self.w_qs = nn.Parameter(torch.empty([n_head, d_model, d_k], dtype=torch.float))\n",
    "        self.w_ks = nn.Parameter(torch.empty([n_head, d_model, d_k], dtype=torch.float))\n",
    "        self.w_vs = nn.Parameter(torch.empty([n_head, d_model, d_v], dtype=torch.float))\n",
    "        # nn.init.xavier_normal_で重みの値を初期化\n",
    "        nn.init.xavier_normal_(self.w_qs)\n",
    "        nn.init.xavier_normal_(self.w_ks)\n",
    "        nn.init.xavier_normal_(self.w_vs)\n",
    "\n",
    "        self.attention = ScaledDotProductAttention(d_model)\n",
    "        self.layer_norm = nn.LayerNorm(d_model) # 各層においてバイアスを除く活性化関数への入力を平均０、分散１に正則化\n",
    "        self.proj = nn.Linear(n_head*d_v, d_model)  # 複数ヘッド分のAttentionの結果を元のサイズに写像するための線形層\n",
    "        # nn.init.xavier_normal_で重みの値を初期化\n",
    "        nn.init.xavier_normal_(self.proj.weight)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "\n",
    "    def forward(self, q, k, v, attn_mask=None):\n",
    "        \"\"\"\n",
    "        :param q: torch.tensor, queryベクトル, \n",
    "            size=(batch_size, len_q, d_model)\n",
    "        :param k: torch.tensor, key, \n",
    "            size=(batch_size, len_k, d_model)\n",
    "        :param v: torch.tensor, valueベクトル, \n",
    "            size=(batch_size, len_v, d_model)\n",
    "        :param attn_mask: torch.tensor, Attentionに適用するマスク, \n",
    "            size=(batch_size, len_q, len_k)\n",
    "        :return outputs: 出力ベクトル, \n",
    "            size=(batch_size, len_q, d_model)\n",
    "        :return attns: Attention\n",
    "            size=(n_head*batch_size, len_q, len_k)\n",
    "            \n",
    "        \"\"\"\n",
    "        d_k, d_v = self.d_k, self.d_v\n",
    "        n_head = self.n_head\n",
    "\n",
    "        # residual connectionのための入力 出力に入力をそのまま加算する\n",
    "        residual = q\n",
    "\n",
    "        batch_size, len_q, d_model = q.size()\n",
    "        batch_size, len_k, d_model = k.size()\n",
    "        batch_size, len_v, d_model = v.size()\n",
    "\n",
    "        # 複数ヘッド化\n",
    "        # torch.repeat または .repeatで指定したdimに沿って同じテンソルを作成\n",
    "        q_s = q.repeat(n_head, 1, 1) # (n_head*batch_size, len_q, d_model)\n",
    "        k_s = k.repeat(n_head, 1, 1) # (n_head*batch_size, len_k, d_model)\n",
    "        v_s = v.repeat(n_head, 1, 1) # (n_head*batch_size, len_v, d_model)\n",
    "        # ヘッドごとに並列計算させるために、n_headをdim=0に、batch_sizeをdim=1に寄せる\n",
    "        q_s = q_s.view(n_head, -1, d_model) # (n_head, batch_size*len_q, d_model)\n",
    "        k_s = k_s.view(n_head, -1, d_model) # (n_head, batch_size*len_k, d_model)\n",
    "        v_s = v_s.view(n_head, -1, d_model) # (n_head, batch_size*len_v, d_model)\n",
    "\n",
    "        # 各ヘッドで線形変換を並列計算(p16左側`Linear`)\n",
    "        q_s = torch.bmm(q_s, self.w_qs)  # (n_head, batch_size*len_q, d_k)\n",
    "        k_s = torch.bmm(k_s, self.w_ks)  # (n_head, batch_size*len_k, d_k)\n",
    "        v_s = torch.bmm(v_s, self.w_vs)  # (n_head, batch_size*len_v, d_v)\n",
    "        # Attentionは各バッチ各ヘッドごとに計算させるためにbatch_sizeをdim=0に寄せる\n",
    "        q_s = q_s.view(-1, len_q, d_k)   # (n_head*batch_size, len_q, d_k)\n",
    "        k_s = k_s.view(-1, len_k, d_k)   # (n_head*batch_size, len_k, d_k)\n",
    "        v_s = v_s.view(-1, len_v, d_v)   # (n_head*batch_size, len_v, d_v)\n",
    "\n",
    "        # Attentionを計算(p16.左側`Scaled Dot-Product Attention * h`)\n",
    "        outputs, attns = self.attention(q_s, k_s, v_s, attn_mask=attn_mask.repeat(n_head, 1, 1))\n",
    "\n",
    "        # 各ヘッドの結果を連結(p16左側`Concat`)\n",
    "        # torch.splitでbatch_sizeごとのn_head個のテンソルに分割\n",
    "        outputs = torch.split(outputs, batch_size, dim=0)  # (batch_size, len_q, d_model) * n_head\n",
    "        # dim=-1で連結\n",
    "        outputs = torch.cat(outputs, dim=-1)  # (batch_size, len_q, d_model*n_head)\n",
    "\n",
    "        # residual connectionのために元の大きさに写像(p16左側`Linear`)\n",
    "        outputs = self.proj(outputs)  # (batch_size, len_q, d_model)\n",
    "        outputs = self.dropout(outputs)\n",
    "        outputs = self.layer_norm(outputs + residual)\n",
    "\n",
    "        return outputs, attns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39d1a04",
   "metadata": {},
   "source": [
    "### ③ Position-Wise Feed Forward Network\n",
    "単語列の位置ごとに独立して処理する2層のネットワークであるPosition-Wise Feed Forward Networkを定義します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8bf12603",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionwiseFeedForward(nn.Module):\n",
    "    \"\"\"\n",
    "    :param d_hid: int, 隠れ層1層目の次元数\n",
    "    :param d_inner_hid: int, 隠れ層2層目の次元数\n",
    "    :param dropout: float, ドロップアウト率\n",
    "    \"\"\"\n",
    "    def __init__(self, d_hid, d_inner_hid, dropout=0.1):\n",
    "        super(PositionwiseFeedForward, self).__init__()\n",
    "        # window size 1のconv層を定義することでPosition wiseな全結合層を実現する.\n",
    "        self.w_1 = nn.Conv1d(d_hid, d_inner_hid, 1)\n",
    "        self.w_2 = nn.Conv1d(d_inner_hid, d_hid, 1)\n",
    "        self.layer_norm = nn.LayerNorm(d_hid)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        :param x: torch.tensor,\n",
    "            size=(batch_size, max_length, d_hid)\n",
    "        :return: torch.tensor,\n",
    "            size=(batch_size, max_length, d_hid) \n",
    "        \"\"\"\n",
    "        residual = x\n",
    "        output = self.relu(self.w_1(x.transpose(1, 2)))\n",
    "        output = self.w_2(output).transpose(2, 1)\n",
    "        output = self.dropout(output)\n",
    "        return self.layer_norm(output + residual)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17be1a89",
   "metadata": {},
   "source": [
    "### ④ Masking\n",
    "TransformerではAttentionに対して２つのマスクを定義します。\n",
    "\n",
    "一つはkey側の系列のPADトークンに対してAttentionを行わないようにするマスクです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6ab02679",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attn_padding_mask(seq_q, seq_k):\n",
    "    \"\"\"\n",
    "    keyのPADに対するattentionを0にするためのマスクを作成する\n",
    "    :param seq_q: tensor, queryの系列, size=(batch_size, len_q)\n",
    "    :param seq_k: tensor, keyの系列, size=(batch_size, len_k)\n",
    "    :return pad_attn_mask: tensor, size=(batch_size, len_q, len_k)\n",
    "    \"\"\"\n",
    "    batch_size, len_q = seq_q.size()\n",
    "    batch_size, len_k = seq_k.size()\n",
    "    pad_attn_mask = seq_k.data.eq(PAD).unsqueeze(1)   # (N, 1, len_k) PAD以外のidを全て0にする\n",
    "    pad_attn_mask = pad_attn_mask.expand(batch_size, len_q, len_k) # (N, len_q, len_k)\n",
    "    return pad_attn_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9bb840e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query:\n",
      " tensor([[1, 2, 3]])\n",
      "key:\n",
      " tensor([[4, 5, 6, 7, 0]])\n",
      "mask:\n",
      " tensor([[[False, False, False, False,  True],\n",
      "         [False, False, False, False,  True],\n",
      "         [False, False, False, False,  True]]])\n"
     ]
    }
   ],
   "source": [
    "_seq_q = torch.tensor([[1, 2, 3]])\n",
    "_seq_k = torch.tensor([[4, 5, 6, 7, PAD]])\n",
    "_mask = get_attn_padding_mask(_seq_q, _seq_k)  # 行がquery、列がkeyに対応し、key側がPAD(=0)の時刻だけ1で他が0の行列ができる\n",
    "print('query:\\n', _seq_q)\n",
    "print('key:\\n', _seq_k)\n",
    "print('mask:\\n', _mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d1f761",
   "metadata": {},
   "source": [
    "もう一つはDecoder側でSelf Attentionを行う際に、各時刻で未来の情報に対するAttentionを行わないようにするマスクです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4c42a7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attn_subsequent_mask(seq):\n",
    "    \"\"\"\n",
    "    未来の情報に対するattentionを0にするためのマスクを作成する\n",
    "    :param seq: tensor, size=(batch_size, length)\n",
    "    :return subsequent_mask: tensor, size=(batch_size, length, length)\n",
    "    \"\"\"\n",
    "    attn_shape = (seq.size(1), seq.size(1))\n",
    "    # 上三角行列(diagonal=1: 対角線より上が1で下が0)\n",
    "    subsequent_mask = torch.triu(torch.ones(attn_shape, dtype=torch.uint8, device=device), diagonal=1)\n",
    "    subsequent_mask = subsequent_mask.repeat(seq.size(0), 1, 1)\n",
    "    return subsequent_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9c0bc50b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seq:\n",
      " tensor([[1, 2, 3, 4]])\n",
      "mask:\n",
      " tensor([[[0, 1, 1, 1],\n",
      "         [0, 0, 1, 1],\n",
      "         [0, 0, 0, 1],\n",
      "         [0, 0, 0, 0]]], dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "_seq = torch.tensor([[1,2,3,4]])\n",
    "_mask = get_attn_subsequent_mask(_seq)  # 行がquery、列がkeyに対応し、queryより未来のkeyの値が1で他は0の行列ができいる\n",
    "print('seq:\\n', _seq)\n",
    "print('mask:\\n', _mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb952e0",
   "metadata": {},
   "source": [
    "## 3. モデルの定義\n",
    "\n",
    "### Encoder\n",
    "これまで定義してきたサブレイヤーを統合して、Encoderを定義します。\n",
    "\n",
    "EncoderではSelf AttentionとPosition-Wise Feed Forward Networkからなるブロックを複数層繰り返すので、ブロックのクラスEncoderLayerを定義した後にEncoderを定義します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2be94e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    \"\"\"Encoderのブロックのクラス\"\"\"\n",
    "    def __init__(self, d_model, d_inner_hid, n_head, d_k, d_v, dropout=0.1):\n",
    "        \"\"\"\n",
    "        :param d_model: int, 隠れ層の次元数\n",
    "        :param d_inner_hid: int, Position Wise Feed Forward Networkの隠れ層2層目の次元数\n",
    "        :param n_head: int,　ヘッド数\n",
    "        :param d_k: int, keyベクトルの次元数\n",
    "        :param d_v: int, valueベクトルの次元数\n",
    "        :param dropout: float, ドロップアウト率\n",
    "        \"\"\"\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        # Encoder内のSelf-Attention\n",
    "        self.slf_attn = MultiHeadAttention(\n",
    "            n_head, d_model, d_k, d_v, dropout=dropout)\n",
    "        # Postionwise FFN\n",
    "        self.pos_ffn = PositionwiseFeedForward(d_model, d_inner_hid, dropout=dropout)\n",
    "\n",
    "    def forward(self, enc_input, slf_attn_mask=None):\n",
    "        \"\"\"\n",
    "        :param enc_input: tensor, Encoderの入力, \n",
    "            size=(batch_size, max_length, d_model)\n",
    "        :param slf_attn_mask: tensor, Self Attentionの行列にかけるマスク, \n",
    "            size=(batch_size, len_q, len_k)\n",
    "        :return enc_output: tensor, Encoderの出力, \n",
    "            size=(batch_size, max_length, d_model)\n",
    "        :return enc_slf_attn: tensor, EncoderのSelf Attentionの行列, \n",
    "            size=(n_head*batch_size, len_q, len_k)\n",
    "        \"\"\"\n",
    "        # Self-Attentionのquery, key, valueにはすべてEncoderの入力（enc_input）が入る\n",
    "        enc_output, enc_slf_attn = self.slf_attn(\n",
    "            enc_input, enc_input, enc_input, attn_mask=slf_attn_mask)\n",
    "        enc_output = self.pos_ffn(enc_output)\n",
    "        return enc_output, enc_slf_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "aad6412e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \"\"\"EncoderLayerブロックからなるEncoderのクラス\"\"\"\n",
    "    def __init__(\n",
    "            self, n_src_vocab, max_length, n_layers=6, n_head=8, d_k=64, d_v=64,\n",
    "            d_word_vec=512, d_model=512, d_inner_hid=1024, dropout=0.1):\n",
    "        \"\"\"\n",
    "        :param n_src_vocab: int, 入力言語の語彙数\n",
    "        :param max_length: int, 最大系列長\n",
    "        :param n_layers: int, レイヤー数\n",
    "        :param n_head: int,　ヘッド数\n",
    "        :param d_k: int, keyベクトルの次元数\n",
    "        :param d_v: int, valueベクトルの次元数\n",
    "        :param d_word_vec: int, 単語の埋め込みの次元数\n",
    "        :param d_model: int, 隠れ層の次元数\n",
    "        :param d_inner_hid: int, Position Wise Feed Forward Networkの隠れ層2層目の次元数\n",
    "        :param dropout: float, ドロップアウト率        \n",
    "        \"\"\"\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        n_position = max_length + 1\n",
    "        self.max_length = max_length\n",
    "        self.d_model = d_model\n",
    "\n",
    "        # Positional Encodingを用いたEmbedding\n",
    "        self.position_enc = nn.Embedding(n_position, d_word_vec, padding_idx=PAD)\n",
    "        self.position_enc.weight.data = position_encoding_init(n_position, d_word_vec)\n",
    "\n",
    "        # 一般的なEmbedding\n",
    "        self.src_word_emb = nn.Embedding(n_src_vocab, d_word_vec, padding_idx=PAD)\n",
    "\n",
    "        # EncoderLayerをn_layers個積み重ねる\n",
    "        self.layer_stack = nn.ModuleList([\n",
    "            EncoderLayer(d_model, d_inner_hid, n_head, d_k, d_v, dropout=dropout)\n",
    "            for _ in range(n_layers)])\n",
    "\n",
    "    def forward(self, src_seq, src_pos):\n",
    "        \"\"\"\n",
    "        :param src_seq: tensor, 入力系列, \n",
    "            size=(batch_size, max_length)\n",
    "        :param src_pos: tensor, 入力系列の各単語の位置情報,\n",
    "            size=(batch_size, max_length)\n",
    "        :return enc_output: tensor, Encoderの最終出力, \n",
    "            size=(batch_size, max_length, d_model)\n",
    "        :return enc_slf_attns: list, EncoderのSelf Attentionの行列のリスト\n",
    "        \"\"\"\n",
    "        # 一般的な単語のEmbeddingを行う\n",
    "        enc_input = self.src_word_emb(src_seq)\n",
    "        # Positional EncodingのEmbeddingを加算する\n",
    "        enc_input += self.position_enc(src_pos)\n",
    "\n",
    "        enc_slf_attns = []\n",
    "        enc_output = enc_input\n",
    "        # key(=enc_input)のPADに対応する部分のみ1のマスクを作成\n",
    "        enc_slf_attn_mask = get_attn_padding_mask(src_seq, src_seq)\n",
    "\n",
    "        # n_layers個のEncoderLayerに入力を通す\n",
    "        for enc_layer in self.layer_stack:\n",
    "            enc_output, enc_slf_attn = enc_layer(\n",
    "                enc_output, slf_attn_mask=enc_slf_attn_mask)\n",
    "            enc_slf_attns += [enc_slf_attn]\n",
    "\n",
    "        return enc_output, enc_slf_attns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8951242b",
   "metadata": {},
   "source": [
    "### Decoder\n",
    "\n",
    "Deocoderも同様にSelf Attention, Source-Target Attention, Position-Wise Feed Forward Networkからなるブロックを複数層繰り返ので、ブロックのクラスDecoderLayerを定義した後にDecoderを定義します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b6d43cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    \"\"\"Decoderのブロックのクラス\"\"\"\n",
    "    def __init__(self, d_model, d_inner_hid, n_head, d_k, d_v, dropout=0.1):\n",
    "        \"\"\"\n",
    "        :param d_model: int, 隠れ層の次元数\n",
    "        :param d_inner_hid: int, Position Wise Feed Forward Networkの隠れ層2層目の次元数\n",
    "        :param n_head: int,　ヘッド数\n",
    "        :param d_k: int, keyベクトルの次元数\n",
    "        :param d_v: int, valueベクトルの次元数\n",
    "        :param dropout: float, ドロップアウト率\n",
    "        \"\"\"\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        # Decoder内のSelf-Attention\n",
    "        self.slf_attn = MultiHeadAttention(n_head, d_model, d_k, d_v, dropout=dropout)\n",
    "        # Encoder-Decoder間のSource-Target Attention\n",
    "        self.enc_attn = MultiHeadAttention(n_head, d_model, d_k, d_v, dropout=dropout)\n",
    "        # Positionwise FFN\n",
    "        self.pos_ffn = PositionwiseFeedForward(d_model, d_inner_hid, dropout=dropout)\n",
    "\n",
    "    def forward(self, dec_input, enc_output, slf_attn_mask=None, dec_enc_attn_mask=None):\n",
    "        \"\"\"\n",
    "        :param dec_input: tensor, Decoderの入力, \n",
    "            size=(batch_size, max_length, d_model)\n",
    "        :param enc_output: tensor, Encoderの出力, \n",
    "            size=(batch_size, max_length, d_model)\n",
    "        :param slf_attn_mask: tensor, Self Attentionの行列にかけるマスク, \n",
    "            size=(batch_size, len_q, len_k)\n",
    "        :param dec_enc_attn_mask: tensor, Soutce-Target Attentionの行列にかけるマスク, \n",
    "            size=(batch_size, len_q, len_k)\n",
    "        :return dec_output: tensor, Decoderの出力, \n",
    "            size=(batch_size, max_length, d_model)\n",
    "        :return dec_slf_attn: tensor, DecoderのSelf Attentionの行列, \n",
    "            size=(n_head*batch_size, len_q, len_k)\n",
    "        :return dec_enc_attn: tensor, DecoderのSoutce-Target Attentionの行列, \n",
    "            size=(n_head*batch_size, len_q, len_k)\n",
    "        \"\"\"\n",
    "        # Self-Attentionのquery, key, valueにはすべてDecoderの入力（dec_input）が入る\n",
    "        dec_output, dec_slf_attn = self.slf_attn(\n",
    "            dec_input, dec_input, dec_input, attn_mask=slf_attn_mask)\n",
    "        # Source-Target-AttentionのqueryにはDecoderの出力(dec_output), key, valueにはEncoderの出力（enc_output）が入る\n",
    "        dec_output, dec_enc_attn = self.enc_attn(\n",
    "            dec_output, enc_output, enc_output, attn_mask=dec_enc_attn_mask)\n",
    "        dec_output = self.pos_ffn(dec_output)\n",
    "\n",
    "        return dec_output, dec_slf_attn, dec_enc_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "28185c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \"\"\"DecoderLayerブロックからなるDecoderのクラス\"\"\"\n",
    "    def __init__(\n",
    "            self, n_tgt_vocab, max_length, n_layers=6, n_head=8, d_k=64, d_v=64,\n",
    "            d_word_vec=512, d_model=512, d_inner_hid=1024, dropout=0.1):\n",
    "        \"\"\"\n",
    "        :param n_tgt_vocab: int, 出力言語の語彙数\n",
    "        :param max_length: int, 最大系列長\n",
    "        :param n_layers: int, レイヤー数\n",
    "        :param n_head: int,　ヘッド数\n",
    "        :param d_k: int, keyベクトルの次元数\n",
    "        :param d_v: int, valueベクトルの次元数\n",
    "        :param d_word_vec: int, 単語の埋め込みの次元数\n",
    "        :param d_model: int, 隠れ層の次元数\n",
    "        :param d_inner_hid: int, Position Wise Feed Forward Networkの隠れ層2層目の次元数\n",
    "        :param dropout: float, ドロップアウト率        \n",
    "        \"\"\"\n",
    "        super(Decoder, self).__init__()\n",
    "        n_position = max_length + 1\n",
    "        self.max_length = max_length\n",
    "        self.d_model = d_model\n",
    "\n",
    "        # Positional Encodingを用いたEmbedding\n",
    "        self.position_enc = nn.Embedding(\n",
    "            n_position, d_word_vec, padding_idx=PAD)\n",
    "        self.position_enc.weight.data = position_encoding_init(n_position, d_word_vec)\n",
    "\n",
    "        # 一般的なEmbedding\n",
    "        self.tgt_word_emb = nn.Embedding(\n",
    "            n_tgt_vocab, d_word_vec, padding_idx=PAD)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # DecoderLayerをn_layers個積み重ねる\n",
    "        self.layer_stack = nn.ModuleList([\n",
    "            DecoderLayer(d_model, d_inner_hid, n_head, d_k, d_v, dropout=dropout)\n",
    "            for _ in range(n_layers)])\n",
    "\n",
    "    def forward(self, tgt_seq, tgt_pos, src_seq, enc_output):\n",
    "        \"\"\"\n",
    "        :param tgt_seq: tensor, 出力系列, \n",
    "            size=(batch_size, max_length)\n",
    "        :param tgt_pos: tensor, 出力系列の各単語の位置情報,\n",
    "            size=(batch_size, max_length)\n",
    "        :param src_seq: tensor, 入力系列, \n",
    "            size=(batch_size, n_src_vocab)\n",
    "        :param enc_output: tensor, Encoderの出力, \n",
    "            size=(batch_size, max_length, d_model)\n",
    "        :return dec_output: tensor, Decoderの最終出力, \n",
    "            size=(batch_size, max_length, d_model)\n",
    "        :return dec_slf_attns: list, DecoderのSelf Attentionの行列のリスト \n",
    "        :return dec_slf_attns: list, DecoderのSelf Attentionの行列のリスト\n",
    "        \"\"\"\n",
    "        # 一般的な単語のEmbeddingを行う\n",
    "        dec_input = self.tgt_word_emb(tgt_seq)\n",
    "        # Positional EncodingのEmbeddingを加算する\n",
    "        dec_input += self.position_enc(tgt_pos)\n",
    "\n",
    "        # Self-Attention用のマスクを作成\n",
    "        # key(=dec_input)のPADに対応する部分が1のマスクと、queryから見たkeyの未来の情報に対応する部分が1のマスクのORをとる\n",
    "        dec_slf_attn_pad_mask = get_attn_padding_mask(tgt_seq, tgt_seq)  # (N, max_length, max_length)\n",
    "        dec_slf_attn_sub_mask = get_attn_subsequent_mask(tgt_seq)  # (N, max_length, max_length)\n",
    "        dec_slf_attn_mask = torch.gt(dec_slf_attn_pad_mask + dec_slf_attn_sub_mask, 0)  # ORをとる\n",
    "\n",
    "        # key(=dec_input)のPADに対応する部分のみ1のマスクを作成\n",
    "        dec_enc_attn_pad_mask = get_attn_padding_mask(tgt_seq, src_seq)  # (N, max_length, max_length)\n",
    "\n",
    "        dec_slf_attns, dec_enc_attns = [], []\n",
    "\n",
    "        dec_output = dec_input\n",
    "        # n_layers個のDecoderLayerに入力を通す\n",
    "        for dec_layer in self.layer_stack:\n",
    "            dec_output, dec_slf_attn, dec_enc_attn = dec_layer(\n",
    "                dec_output, enc_output,\n",
    "                slf_attn_mask=dec_slf_attn_mask,\n",
    "                dec_enc_attn_mask=dec_enc_attn_pad_mask)\n",
    "\n",
    "            dec_slf_attns += [dec_slf_attn]\n",
    "            dec_enc_attns += [dec_enc_attn]\n",
    "\n",
    "        return dec_output, dec_slf_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e69ad9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    \"\"\"Transformerのモデル全体のクラス\"\"\"\n",
    "    def __init__(\n",
    "            self, n_src_vocab, n_tgt_vocab, max_length, n_layers=6, n_head=8,\n",
    "            d_word_vec=512, d_model=512, d_inner_hid=1024, d_k=64, d_v=64,\n",
    "            dropout=0.1, proj_share_weight=True):\n",
    "        \"\"\"\n",
    "        :param n_src_vocab: int, 入力言語の語彙数\n",
    "        :param n_tgt_vocab: int, 出力言語の語彙数\n",
    "        :param max_length: int, 最大系列長\n",
    "        :param n_layers: int, レイヤー数\n",
    "        :param n_head: int,　ヘッド数\n",
    "        :param d_k: int, keyベクトルの次元数\n",
    "        :param d_v: int, valueベクトルの次元数\n",
    "        :param d_word_vec: int, 単語の埋め込みの次元数\n",
    "        :param d_model: int, 隠れ層の次元数\n",
    "        :param d_inner_hid: int, Position Wise Feed Forward Networkの隠れ層2層目の次元数\n",
    "        :param dropout: float, ドロップアウト率        \n",
    "        :param proj_share_weight: bool, 出力言語の単語のEmbeddingと出力の写像で重みを共有する        \n",
    "        \"\"\"\n",
    "        super(Transformer, self).__init__()\n",
    "        self.encoder = Encoder(\n",
    "            n_src_vocab, max_length, n_layers=n_layers, n_head=n_head,\n",
    "            d_word_vec=d_word_vec, d_model=d_model,\n",
    "            d_inner_hid=d_inner_hid, dropout=dropout)\n",
    "        self.decoder = Decoder(\n",
    "            n_tgt_vocab, max_length, n_layers=n_layers, n_head=n_head,\n",
    "            d_word_vec=d_word_vec, d_model=d_model,\n",
    "            d_inner_hid=d_inner_hid, dropout=dropout)\n",
    "        self.tgt_word_proj = nn.Linear(d_model, n_tgt_vocab, bias=False)\n",
    "        nn.init.xavier_normal_(self.tgt_word_proj.weight)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        assert d_model == d_word_vec  # 各モジュールの出力のサイズは揃える\n",
    "\n",
    "        if proj_share_weight:\n",
    "            # 出力言語の単語のEmbeddingと出力の写像で重みを共有する\n",
    "            assert d_model == d_word_vec\n",
    "            self.tgt_word_proj.weight = self.decoder.tgt_word_emb.weight\n",
    "\n",
    "    def get_trainable_parameters(self):\n",
    "        # Positional Encoding以外のパラメータを更新する\n",
    "        enc_freezed_param_ids = set(map(id, self.encoder.position_enc.parameters()))\n",
    "        dec_freezed_param_ids = set(map(id, self.decoder.position_enc.parameters()))\n",
    "        freezed_param_ids = enc_freezed_param_ids | dec_freezed_param_ids\n",
    "        return (p for p in self.parameters() if id(p) not in freezed_param_ids)\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        src_seq, src_pos = src\n",
    "        tgt_seq, tgt_pos = tgt\n",
    "\n",
    "        src_seq = src_seq[:, 1:]\n",
    "        src_pos = src_pos[:, 1:]\n",
    "        tgt_seq = tgt_seq[:, :-1]\n",
    "        tgt_pos = tgt_pos[:, :-1]\n",
    "\n",
    "        enc_output, *_ = self.encoder(src_seq, src_pos)\n",
    "        dec_output, *_ = self.decoder(tgt_seq, tgt_pos, src_seq, enc_output)\n",
    "        seq_logit = self.tgt_word_proj(dec_output)\n",
    "\n",
    "        return seq_logit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ae9e77",
   "metadata": {},
   "source": [
    "## 4. 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9cde92f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(batch_X, batch_Y, model, criterion, optimizer=None, is_train=True):\n",
    "    # バッチの損失を計算\n",
    "    model.train(is_train)\n",
    "    \n",
    "    pred_Y = model(batch_X, batch_Y)\n",
    "    gold = batch_Y[0][:, 1:].contiguous()\n",
    "#     gold = batch_Y[0].contiguous()\n",
    "    loss = criterion(pred_Y.view(-1, pred_Y.size(2)), gold.view(-1))\n",
    "\n",
    "    if is_train:  # 訓練時はパラメータを更新\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    gold = gold.data.cpu().numpy().tolist()\n",
    "    pred = pred_Y.max(dim=-1)[1].data.cpu().numpy().tolist()\n",
    "\n",
    "    return loss.item(), gold, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b2ddcdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 20\n",
    "batch_size = 64\n",
    "num_epochs = 15\n",
    "lr = 0.001\n",
    "ckpt_path = 'transformer.pth'\n",
    "max_length = MAX_LENGTH + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2fa8e571",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args = {\n",
    "    'n_src_vocab': vocab_size_X,\n",
    "    'n_tgt_vocab': vocab_size_Y,\n",
    "    'max_length': max_length,\n",
    "    'proj_share_weight': True,\n",
    "    'd_k': 32,\n",
    "    'd_v': 32,\n",
    "    'd_model': 128,\n",
    "    'd_word_vec': 128,\n",
    "    'd_inner_hid': 256,\n",
    "    'n_layers': 3,\n",
    "    'n_head': 6,\n",
    "    'dropout': 0.1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f316602f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\takas\\anaconda3\\envs\\ml\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "# DataLoaderやモデルを定義\n",
    "train_dataloader = DataLoader(\n",
    "    train_X, train_Y, batch_size\n",
    "    )\n",
    "valid_dataloader = DataLoader(\n",
    "    valid_X, valid_Y, batch_size, \n",
    "    shuffle=False\n",
    "    )\n",
    "\n",
    "model = Transformer(**model_args).to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.get_trainable_parameters(), lr=lr)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD, size_average=False).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "37272066",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_bleu(refs, hyps):\n",
    "    \"\"\"\n",
    "    BLEUスコアを計算する関数\n",
    "    :param refs: list, 参照訳。単語のリストのリスト (例： [['I', 'have', 'a', 'pen'], ...])\n",
    "    :param hyps: list, モデルの生成した訳。単語のリストのリスト (例： [['I', 'have', 'a', 'pen'], ...])\n",
    "    :return: float, BLEUスコア(0~100)\n",
    "    \"\"\"\n",
    "    refs = [[ref[:ref.index(EOS)]] for ref in refs]\n",
    "    hyps = [hyp[:hyp.index(EOS)] if EOS in hyp else hyp for hyp in hyps]\n",
    "    return 100 * bleu_score.corpus_bleu(refs, hyps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "30bf49d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 [3.3min]: train_loss: 77.49  train_bleu: 4.61  valid_loss: 41.30  valid_bleu: 10.62\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 2 [3.3min]: train_loss: 39.31  train_bleu: 12.33  valid_loss: 32.10  valid_bleu: 17.69\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 3 [3.3min]: train_loss: 31.82  train_bleu: 18.13  valid_loss: 28.00  valid_bleu: 22.11\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 4 [3.3min]: train_loss: 28.15  train_bleu: 21.78  valid_loss: 25.68  valid_bleu: 24.99\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 5 [3.3min]: train_loss: 25.71  train_bleu: 24.50  valid_loss: 24.28  valid_bleu: 26.83\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 6 [3.3min]: train_loss: 23.88  train_bleu: 26.84  valid_loss: 22.91  valid_bleu: 29.09\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 7 [3.3min]: train_loss: 22.47  train_bleu: 28.63  valid_loss: 22.16  valid_bleu: 30.10\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 8 [3.3min]: train_loss: 21.33  train_bleu: 30.11  valid_loss: 21.56  valid_bleu: 31.04\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 9 [3.3min]: train_loss: 20.27  train_bleu: 31.56  valid_loss: 20.99  valid_bleu: 31.99\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 10 [3.3min]: train_loss: 19.41  train_bleu: 32.76  valid_loss: 20.31  valid_bleu: 33.36\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 11 [3.3min]: train_loss: 18.66  train_bleu: 33.90  valid_loss: 20.08  valid_bleu: 33.48\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 12 [3.3min]: train_loss: 17.92  train_bleu: 35.04  valid_loss: 19.86  valid_bleu: 33.88\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 13 [3.3min]: train_loss: 17.29  train_bleu: 35.99  valid_loss: 19.30  valid_bleu: 34.98\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 14 [3.3min]: train_loss: 16.73  train_bleu: 36.89  valid_loss: 19.30  valid_bleu: 34.72\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 15 [3.3min]: train_loss: 16.22  train_bleu: 37.64  valid_loss: 19.00  valid_bleu: 35.49\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 訓練\n",
    "best_valid_bleu = 0.\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    start = time.time()\n",
    "    train_loss = 0.\n",
    "    train_refs = []\n",
    "    train_hyps = []\n",
    "    valid_loss = 0.\n",
    "    valid_refs = []\n",
    "    valid_hyps = []\n",
    "    # train\n",
    "    for batch in train_dataloader:\n",
    "        batch_X, batch_Y = batch\n",
    "        loss, gold, pred = compute_loss(\n",
    "            batch_X, batch_Y, model, criterion, optimizer, is_train=True\n",
    "            )\n",
    "        train_loss += loss\n",
    "        train_refs += gold\n",
    "        train_hyps += pred\n",
    "    # valid\n",
    "    for batch in valid_dataloader:\n",
    "        batch_X, batch_Y = batch\n",
    "        loss, gold, pred = compute_loss(\n",
    "            batch_X, batch_Y, model, criterion, is_train=False\n",
    "            )\n",
    "        valid_loss += loss\n",
    "        valid_refs += gold\n",
    "        valid_hyps += pred\n",
    "    # 損失をサンプル数で割って正規化\n",
    "    train_loss /= len(train_dataloader.data) \n",
    "    valid_loss /= len(valid_dataloader.data) \n",
    "    # BLEUを計算\n",
    "    train_bleu = calc_bleu(train_refs, train_hyps)\n",
    "    valid_bleu = calc_bleu(valid_refs, valid_hyps)\n",
    "\n",
    "    # validationデータでBLEUが改善した場合にはモデルを保存\n",
    "    if valid_bleu > best_valid_bleu:\n",
    "        ckpt = model.to('cpu').state_dict()\n",
    "        torch.save(ckpt, ckpt_path)\n",
    "        best_valid_bleu = valid_bleu\n",
    "\n",
    "    elapsed_time = (time.time()-start) / 60\n",
    "    print('Epoch {} [{:.1f}min]: train_loss: {:5.2f}  train_bleu: {:2.2f}  valid_loss: {:5.2f}  valid_bleu: {:2.2f}'.format(\n",
    "            epoch, elapsed_time, train_loss, train_bleu, valid_loss, valid_bleu))\n",
    "    print('-'*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9941f8d6",
   "metadata": {},
   "source": [
    "## 5. 評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ffeaab86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, src, max_length=20):\n",
    "    # 学習済みモデルで系列を生成する\n",
    "    model.eval()\n",
    "    \n",
    "    src_seq, src_pos = src\n",
    "    batch_size = src_seq.size(0)\n",
    "    enc_output, enc_slf_attns = model.encoder(src_seq, src_pos)\n",
    "        \n",
    "    tgt_seq = torch.full([batch_size, 1], BOS, dtype=torch.long, device=device)\n",
    "    tgt_pos = torch.arange(1, dtype=torch.long, device=device)\n",
    "    tgt_pos = tgt_pos.unsqueeze(0).repeat(batch_size, 1)\n",
    "\n",
    "    # 時刻ごとに処理\n",
    "    for t in range(1, max_length+1):\n",
    "        dec_output, dec_slf_attns, dec_enc_attns = model.decoder(\n",
    "            tgt_seq, tgt_pos, src_seq, enc_output)\n",
    "        dec_output = model.tgt_word_proj(dec_output)\n",
    "        out = dec_output[:, -1, :].max(dim=-1)[1].unsqueeze(1)\n",
    "        # 自身の出力を次の時刻の入力にする\n",
    "        tgt_seq = torch.cat([tgt_seq, out], dim=-1)\n",
    "        tgt_pos = torch.arange(t+1, dtype=torch.long, device=device)\n",
    "        tgt_pos = tgt_pos.unsqueeze(0).repeat(batch_size, 1)\n",
    "\n",
    "    return tgt_seq[:, 1:], enc_slf_attns, dec_slf_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c7b73d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ids_to_sentence(vocab, ids):\n",
    "    # IDのリストを単語のリストに変換する\n",
    "    return [vocab.id2word[_id] for _id in ids]\n",
    "\n",
    "def trim_eos(ids):\n",
    "    # IDのリストからEOS以降の単語を除外する\n",
    "    if EOS in ids:\n",
    "        return ids[:ids.index(EOS)]\n",
    "    else:\n",
    "        return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9937babe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 学習済みモデルの読み込み\n",
    "model = Transformer(**model_args).to(device)\n",
    "ckpt = torch.load(ckpt_path , map_location=torch.device('cpu'))\n",
    "model.load_state_dict(ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8b35e347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# テストデータの読み込み\n",
    "test_X = load_data('./data/dev.en')\n",
    "test_Y = load_data('./data/dev.ja')\n",
    "test_X = [sentence_to_ids(vocab_X, sentence) for sentence in test_X]\n",
    "test_Y = [sentence_to_ids(vocab_Y, sentence) for sentence in test_Y]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c69ff5",
   "metadata": {},
   "source": [
    "### 生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "dd8aa048",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(\n",
    "    test_X, test_Y, 1,\n",
    "    shuffle=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e7c44fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src: show your own business .\n",
      "tgt: 自分 の 事 を しろ 。\n",
      "out: あなた の 顔 を <UNK> し て い た い 。\n"
     ]
    }
   ],
   "source": [
    "src, tgt = next(test_dataloader)\n",
    "\n",
    "src_ids = src[0][0].cpu().numpy()\n",
    "tgt_ids = tgt[0][0].cpu().numpy()\n",
    "\n",
    "print('src: {}'.format(' '.join(ids_to_sentence(vocab_X, src_ids[1:-1]))))\n",
    "print('tgt: {}'.format(' '.join(ids_to_sentence(vocab_Y, tgt_ids[1:-1]))))\n",
    "\n",
    "preds, enc_slf_attns, dec_slf_attns, dec_enc_attns = test(model, src)\n",
    "pred_ids = preds[0].data.cpu().numpy().tolist()\n",
    "print('out: {}'.format(' '.join(ids_to_sentence(vocab_Y, trim_eos(pred_ids)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18814173",
   "metadata": {},
   "source": [
    "## BLEUの評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0d7aa766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.603488346979837\n"
     ]
    }
   ],
   "source": [
    "# BLEUの評価\n",
    "test_dataloader = DataLoader(\n",
    "    test_X, test_Y, 128,\n",
    "    shuffle=False\n",
    "    )\n",
    "refs_list = []\n",
    "hyp_list = []\n",
    "\n",
    "for batch in test_dataloader:\n",
    "    batch_X, batch_Y = batch\n",
    "    preds, *_ = test(model, batch_X)\n",
    "    preds = preds.data.cpu().numpy().tolist()\n",
    "    refs = batch_Y[0].data.cpu().numpy()[:, 1:].tolist()\n",
    "    refs_list += refs\n",
    "    hyp_list += preds\n",
    "bleu = calc_bleu(refs_list, hyp_list)\n",
    "print(bleu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e99eaea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c668ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11c8df1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
