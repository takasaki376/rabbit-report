{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66008998",
   "metadata": {},
   "source": [
    "# Section4：応用モデル"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6785c7a9",
   "metadata": {},
   "source": [
    "# 提案⼿法\n",
    "- ディープラーニングモデルは精度は良いが、その分ネットワークが深くなり計算量が増える。\n",
    "- 計算量が増えると、多くの計算リソースが必要で、お⾦がかかってしまう。\n",
    "- ディープラーニングモデルの軽量化・⾼速化・⾼精度化を実現 (その名の通りモバイルなネットワーク)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715e3a12",
   "metadata": {},
   "source": [
    "## 一般的な畳み込みレイヤー\n",
    "\n",
    "入力マップ：$H \\times W \\times C$ \\\n",
    "カーネル：$K \\times K \\times C$ \\\n",
    "出力マップ：$H \\times W \\times M$ \n",
    "\n",
    "ストライド１でパディングありの場合の１つの点での計算量は、$K \\times K \\times C \\times M$ \\\n",
    "出力マップ全体すると、$H \\times W \\times K \\times K \\times C \\times M$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6661992",
   "metadata": {},
   "source": [
    "## 4.1 MobileNets\n",
    "Depthwise ConvolutionとPointwise Convolutionの組み合わせで軽量化を実現する\n",
    "\n",
    "### Depthwise Convolution\n",
    "-  仕組み\n",
    " - ⼊⼒マップのチャネルごとに畳み込みを実施\n",
    " - 出⼒マップをそれらと結合 (⼊⼒マップのチャネル数と同じになる)\n",
    " \n",
    "チャンネルごとに畳み込みをするため、チャンネル間の関連性は考慮されない。\n",
    "\n",
    "入力マップ：$H \\times W \\times C$ \\\n",
    "カーネル：$K \\times K \\times 1$ （フィルタ数は１固定）\\\n",
    "出力マップ：$H \\times W \\times C$\n",
    "\n",
    "出力マップの計算量は：$H \\times W \\times C \\times K \\times K$\n",
    "\n",
    "### Pointwise Convolution\n",
    "- 仕組み\n",
    " -  1 x 1 convとも呼ばれる (正確には1 x 1 x c)\n",
    " - ⼊⼒マップのポイントごとに畳み込みを実施\n",
    " - 出⼒マップ(チャネル数)はフィルタ数分だけ作成可能 (任意のサイズが指定可能)\n",
    " \n",
    "入力マップ：$H \\times W\\times C$ \\\n",
    "カーネル：$1 \\times 1 \\times C$ \\\n",
    "出力マップ：$H \\times W \\times M$\n",
    "\n",
    "出力マップの計算量は：$H\\times W\\times C\\times M$\n",
    "\n",
    "### MobileNetのアーキテクチャ\n",
    "- Depthwise Separable Convolutionという⼿法を⽤いて計算量を削減している。通常の畳込みが空間⽅向とチャネル⽅向の計算を同時に⾏うのに対して、Depthwise Separable ConvolutionではそれらをDepthwise ConvolutionとPointwise Convolutionと呼ばれる演算によって個別に⾏う。\n",
    "- Depthwise Convolitionはチャネル毎に空間⽅向へ畳み込む。すなわち、チャネル毎に$D_K \\times D_K \\times 1$のサイズのフィルターをそれぞれ⽤いて計算を⾏うため、その計算量は$H \\times W \\times C \\times D_K \\times D_K $となる。\n",
    "- 次にDepthwise Convolutionの出⼒をPointwise Convolutionによってチャネル⽅向に畳み込む。すなわち、出⼒チャネル毎に$1 \\times 1 \\times M$サイズのフィルターをそれぞれ⽤いて計算を⾏うため、その計算量は$H \\times W \\times C \\times M$となる。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a72c0c",
   "metadata": {},
   "source": [
    "## 4.2 DenseNet\n",
    "Dense Convolutional Network（以下、DenseNet）は、畳込みニューラルネットワーク（以下、CNN）アーキテクチャの⼀種である。ニューラルネットワークでは層が深くなるにつれて、学習が難しくなるという問題があったが、Residual Network（以下、ResNet）などのCNNアーキテクチャでは前⽅の層から後⽅の層へアイデンティティ接続を介してパスを作ることで問題を対処した。DenseBlockと呼ばれるモジュールを⽤いた、DenseNetもそのようなアーキテクチャの⼀つである。\n",
    "\n",
    "- 初期の畳み込み\n",
    "- Denseブロック\n",
    "- 変換レイヤー\n",
    "- 判別レイヤー\n",
    "\n",
    "### Dense Block\n",
    "\n",
    "#### 出⼒層に前の層の⼊⼒を⾜しあわせる\n",
    "- 層間の情報の伝達を最⼤にするために全ての同特徴量サイズの層を結合する\n",
    "\n",
    "#### 特徴マップの⼊⼒に対し、下記の処理で出⼒を計算\n",
    "- Batch正規化\n",
    "- Relu関数による変換\n",
    "- 3 x 3畳み込み層による処理\n",
    "\n",
    "#### kをネットワークのgrowth rateと呼ぶ\n",
    "- kが⼤きくなるほど、ネットワークが⼤きくなるため、⼩さな整数に設定するのがよい\n",
    "\n",
    "###  Transition Layer\n",
    "- CNNでは中間層でチャネルサイズを変更し\n",
    "- 特徴マップのサイズを変更し、ダウンサンプリングを⾏うため、Transition Layerと呼ばれる層でDence blockをつなぐ\n",
    "\n",
    "### DenseNetとResNetの違い\n",
    "- DenseBlockでは前⽅の各層からの出⼒全てが後⽅の層への⼊⼒として⽤いられる\n",
    "- RessidualBlockでは前1層の⼊⼒のみ後⽅の層へ⼊⼒\n",
    "\n",
    "### 正規化\n",
    "\n",
    "#### Batch Norm\n",
    "- ミニバッチに含まれるsampleの同⼀チャネルが同⼀分布に従うよう正規化\n",
    " - H x W x CのsampleがN個あった場合に、N個の同⼀チャネルが正規化の単位\n",
    " - RGBの3チャネルのsampleがN個の場合は、それぞれのチャンネルの平均と分散を求め正規化を実施 (図の⻘い部分に対応)。チャンネルごとに正規化された特徴マップを出⼒。\n",
    " - Batch Normalizationはニューラルネットワークにおいて学習時間の短縮や初期値への依存低減、過学習の抑制など効果がある。\n",
    "- 問題点\n",
    " - Batch Sizeが⼩さい条件下では、学習が収束しないことがあり、代わりにLayer Normalizationなどの正規化⼿法が使われることが多い。\n",
    " \n",
    "#### Layer Norm\n",
    "- それぞれのsampleの全てのpixelsが同⼀分布に従うよう正規化\n",
    " -  N個のsampleのうち⼀つに注⽬。H x W x Cの全てのpixelが正規化の単位。\n",
    " -  RGBの3チャネルのsampleがN個の場合は、あるsampleを取り出し、全てのチャネルの平均と分散を求め正規化を実施 (図の⻘い部分に対応)。特徴マップごとに正規化された特徴マップを出⼒\n",
    " -  ミニバッチの数に依存しないので、上記の問題を解消できていると考えられる。\n",
    " \n",
    "#### Instance Nrom\n",
    "- さらにchannelも同⼀分布に従うよう正規化\n",
    " - 各sampleをチャンネルを ごとに正規化\n",
    " - コントラストの正規化に寄与・画像のスタイル転送やテクスチャ合成タスクなどで利用\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe7b221",
   "metadata": {},
   "source": [
    "## 4.3 Wavenet\n",
    "- 生の音声波形を生成する深層学習モデル\n",
    "- Pixel CNN（高解像度の画像を精密に生成できる手法）を音声に応用したもの\n",
    "- 時系列データに対して畳み込み（Dilated convolution）を適用する。\n",
    "- Dilated convolution\n",
    " - 層が深くなるにつれて畳み込むリンクを離す\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06734a2",
   "metadata": {},
   "source": [
    "# 確認テスト"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9998797c",
   "metadata": {},
   "source": [
    "#### P86\n",
    "問）\n",
    "- Depthwise Convolitionはチャネル毎に空間⽅向へ畳み込む。すなわち、チャネル毎に$D_K \\times D_K \\times 1$のサイズのフィルターをそれぞれ⽤いて計算を⾏うため、その計算量は（い）となる。\n",
    "- 次にDepthwise Convolutionの出⼒をPointwise Convolutionによってチャネル⽅向に畳み込む。すなわち、出⼒チャネル毎に$1 \\times 1 \\times M$サイズのフィルターをそれぞれ⽤いて計算を⾏うため、その計算量は（う）となる。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1509e0",
   "metadata": {},
   "source": [
    "答） \n",
    "\n",
    "- （い）：$H \\times W \\times C \\times D_K \\times D_K $\n",
    "- （う）：$H \\times W \\times C \\times M$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e21779",
   "metadata": {},
   "source": [
    "#### P106\n",
    "深層学習を⽤いて結合確率を学習する際に、効率的に学習が⾏えるアーキテクチャを提案したことが WaveNet の⼤きな貢献の1 つである。提案された新しい Convolution 型アーキテクチャは（あ）と呼ばれ、結合確率を効率的に学習できるようになっている。\n",
    "\n",
    "- Dilated causal convolution\n",
    "- Depthwise separable convolution　⇒MobileNetで使われている\n",
    "- Pointwise convolution　　　　　　 ⇒MobileNetで使われている\n",
    "- Deconvolution　　　　　　　　　　⇒逆畳み込み演算"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f4aa13",
   "metadata": {},
   "source": [
    "（あ）を⽤いた際の⼤きな利点は、単純な Convolution layer と⽐べて（い）ことである。\n",
    "\n",
    "- パラメータ数に対する受容野が広い\n",
    "- 受容野あたりのパラメータ数が多い　　⇒パラメータ数は減っているため違う\n",
    "- 学習時に並列計算が⾏える　　　　　⇒並列演算はできない。\n",
    "- 推論時に並列計算が⾏える　　　　　⇒並列演算はできない。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28af25a",
   "metadata": {},
   "source": [
    "答） \n",
    "\n",
    "- （あ）：Dilated causal convolution\n",
    "- （い）：パラメータ数に対する受容野が広い"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b884b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
